{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720ef5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "준비 완료\n",
      "EXP_NAME: sparse_rcnn_r50_1024_stage_aug14\n",
      "IMAGE_SIZE: (1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 이 셀은 노트북에서 가장 먼저 실행하는 공통 준비 셀입니다.\n",
    "# 경로, 클래스, 시드, 기본 상수를 한 곳에서 관리하기 위해 분리했습니다.\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1) 데이터 루트 경로를 설정합니다.\n",
    "#    AI Stages 환경에서 사용자가 쓰던 경로 패턴을 그대로 맞췄습니다.\n",
    "FULL_DATA_ROOT = Path(\"/data/ephemeral/home/model/dataset\")\n",
    "\n",
    "# 2) 원본 train.json 경로를 지정합니다.\n",
    "#    train/val split을 새로 만들기 위해 필요합니다.\n",
    "TRAIN_JSON = FULL_DATA_ROOT / \"train.json\"\n",
    "\n",
    "# 3) test.json 경로를 지정합니다.\n",
    "#    추론 시 샘플 제출 파일을 만들 때 필요합니다.\n",
    "TEST_JSON = FULL_DATA_ROOT / \"test.json\"\n",
    "\n",
    "# 4) sample_submission 폴더 경로를 지정합니다.\n",
    "SAMPLE_SUB_DIR = Path(\"/data/ephemeral/home/model/sample_submission\")\n",
    "\n",
    "# 5) 실험 결과가 저장될 work_dirs 루트를 지정합니다.\n",
    "WORK_DIR_ROOT = Path(\"/data/ephemeral/home/model/work_dirs_single\")\n",
    "\n",
    "# 6) 이번 실험의 모델 이름(폴더명)입니다.\n",
    "#    학습/추론 셀에서 반드시 동일하게 사용해야 체크포인트를 찾습니다.\n",
    "EXP_NAME = \"sparse_rcnn_r50_1024_stage_aug14\"\n",
    "\n",
    "# 7) 입력 이미지 크기를 통일해서 실험 변수를 줄입니다.\n",
    "#    사용자의 기존 1024 전략을 유지합니다.\n",
    "IMAGE_SIZE = (1024, 1024)\n",
    "\n",
    "# 8) 클래스 정의를 대회 포맷에 맞춰 고정합니다.\n",
    "CLASSES = (\n",
    "    \"General trash\",\n",
    "    \"Paper\",\n",
    "    \"Paper pack\",\n",
    "    \"Metal\",\n",
    "    \"Glass\",\n",
    "    \"Plastic\",\n",
    "    \"Styrofoam\",\n",
    "    \"Plastic bag\",\n",
    "    \"Battery\",\n",
    "    \"Clothing\",\n",
    ")\n",
    "\n",
    "# 9) 재현성을 위해 시드를 고정합니다.\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    # 파이썬 기본 랜덤 시드 고정\n",
    "    random.seed(seed)\n",
    "    # 넘파이 랜덤 시드 고정\n",
    "    np.random.seed(seed)\n",
    "    # 해시 기반 연산 시드 고정\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "# 10) 경로 존재 여부를 사전에 확인해 불필요한 런타임 오류를 줄입니다.\n",
    "assert TRAIN_JSON.exists(), f\"train.json 없음: {TRAIN_JSON}\"\n",
    "assert TEST_JSON.exists(), f\"test.json 없음: {TEST_JSON}\"\n",
    "assert SAMPLE_SUB_DIR.exists(), f\"sample_submission 폴더 없음: {SAMPLE_SUB_DIR}\"\n",
    "\n",
    "print(\"준비 완료\")\n",
    "print(\"EXP_NAME:\", EXP_NAME)\n",
    "print(\"IMAGE_SIZE:\", IMAGE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8aa6ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: /data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14/epoch_14.pth\n",
      "12/08 14:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1608637542\n",
      "    GPU 0: Tesla V100-SXM2-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu121\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1608637542\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: gcc: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/08 14:17:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = '/data/ephemeral/home/model/dataset'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = '/data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14/epoch_14.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 36\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        frozen_stages=1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        add_extra_convs='on_input',\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=4,\n",
      "        out_channels=256,\n",
      "        start_level=0,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=2, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=6,\n",
      "        proposal_feature_channel=256,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "        ],\n",
      "        type='SparseRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        num_proposals=300,\n",
      "        proposal_feature_channel=256,\n",
      "        type='EmbeddingRPNHead'),\n",
      "    test_cfg=dict(rcnn=dict(max_per_img=300), rpn=None),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "        ],\n",
      "        rpn=None),\n",
      "    type='SparseRCNN')\n",
      "num_proposals = 300\n",
      "num_stages = 6\n",
      "optim_wrapper = None\n",
      "param_scheduler = None\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='/data/ephemeral/home/model/dataset/test.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='/data/ephemeral/home/model/dataset',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='/data/ephemeral/home/model/dataset/test.json',\n",
      "    format_only=True,\n",
      "    metric='bbox',\n",
      "    outfile_prefix=\n",
      "    '/data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14/sparse_rcnn_r50_1024_stage_aug14_test',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = None\n",
      "train_dataloader = None\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            480,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            512,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            544,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            576,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            608,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            640,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            672,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            704,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            736,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            768,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            800,\n",
      "                            1333,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            400,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            500,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            600,\n",
      "                            1333,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "                dict(\n",
      "                    allow_negative_crop=True,\n",
      "                    crop_size=(\n",
      "                        384,\n",
      "                        600,\n",
      "                    ),\n",
      "                    crop_type='absolute_range',\n",
      "                    type='RandomCrop'),\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            480,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            512,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            544,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            576,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            608,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            640,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            672,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            704,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            736,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            768,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            800,\n",
      "                            1333,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "            ],\n",
      "        ],\n",
      "        type='RandomChoice'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = None\n",
      "val_dataloader = None\n",
      "val_evaluator = None\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14'\n",
      "\n",
      "12/08 14:17:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "12/08 14:17:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loads checkpoint by local backend from path: /data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14/epoch_14.pth\n",
      "12/08 14:17:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14/epoch_14.pth\n",
      "12/08 14:17:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [  50/4871]    eta: 0:05:54  time: 0.0735  data_time: 0.0039  memory: 761  \n",
      "12/08 14:17:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 100/4871]    eta: 0:05:12  time: 0.0577  data_time: 0.0019  memory: 761  \n",
      "12/08 14:17:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 150/4871]    eta: 0:04:56  time: 0.0575  data_time: 0.0019  memory: 761  \n",
      "12/08 14:17:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 200/4871]    eta: 0:04:46  time: 0.0570  data_time: 0.0018  memory: 761  \n",
      "12/08 14:17:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 250/4871]    eta: 0:04:39  time: 0.0571  data_time: 0.0018  memory: 761  \n",
      "12/08 14:17:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 300/4871]    eta: 0:04:34  time: 0.0578  data_time: 0.0020  memory: 761  \n",
      "12/08 14:17:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 350/4871]    eta: 0:04:30  time: 0.0578  data_time: 0.0019  memory: 761  \n",
      "12/08 14:17:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 400/4871]    eta: 0:04:26  time: 0.0577  data_time: 0.0018  memory: 761  \n",
      "12/08 14:18:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 450/4871]    eta: 0:04:22  time: 0.0578  data_time: 0.0019  memory: 761  \n",
      "12/08 14:18:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 500/4871]    eta: 0:04:18  time: 0.0569  data_time: 0.0018  memory: 761  \n",
      "12/08 14:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 550/4871]    eta: 0:04:14  time: 0.0580  data_time: 0.0020  memory: 761  \n",
      "12/08 14:18:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 600/4871]    eta: 0:04:11  time: 0.0580  data_time: 0.0019  memory: 761  \n",
      "12/08 14:18:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 650/4871]    eta: 0:04:08  time: 0.0593  data_time: 0.0020  memory: 761  \n",
      "12/08 14:18:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 700/4871]    eta: 0:04:05  time: 0.0579  data_time: 0.0018  memory: 761  \n",
      "12/08 14:18:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 750/4871]    eta: 0:04:02  time: 0.0584  data_time: 0.0019  memory: 761  \n",
      "12/08 14:18:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 800/4871]    eta: 0:04:00  time: 0.0644  data_time: 0.0019  memory: 761  \n",
      "12/08 14:18:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 850/4871]    eta: 0:03:59  time: 0.0648  data_time: 0.0024  memory: 761  \n",
      "12/08 14:18:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 900/4871]    eta: 0:03:57  time: 0.0629  data_time: 0.0022  memory: 761  \n",
      "12/08 14:18:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 950/4871]    eta: 0:03:54  time: 0.0612  data_time: 0.0019  memory: 761  \n",
      "12/08 14:18:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1000/4871]    eta: 0:03:50  time: 0.0573  data_time: 0.0017  memory: 761  \n",
      "12/08 14:18:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1050/4871]    eta: 0:03:47  time: 0.0580  data_time: 0.0018  memory: 761  \n",
      "12/08 14:18:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1100/4871]    eta: 0:03:44  time: 0.0577  data_time: 0.0018  memory: 761  \n",
      "12/08 14:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1150/4871]    eta: 0:03:41  time: 0.0582  data_time: 0.0018  memory: 761  \n",
      "12/08 14:18:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1200/4871]    eta: 0:03:37  time: 0.0569  data_time: 0.0017  memory: 761  \n",
      "12/08 14:18:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1250/4871]    eta: 0:03:34  time: 0.0570  data_time: 0.0017  memory: 761  \n",
      "12/08 14:18:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1300/4871]    eta: 0:03:31  time: 0.0583  data_time: 0.0020  memory: 761  \n",
      "12/08 14:18:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1350/4871]    eta: 0:03:28  time: 0.0591  data_time: 0.0018  memory: 761  \n",
      "12/08 14:18:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1400/4871]    eta: 0:03:25  time: 0.0574  data_time: 0.0017  memory: 761  \n",
      "12/08 14:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1450/4871]    eta: 0:03:22  time: 0.0579  data_time: 0.0017  memory: 761  \n",
      "12/08 14:19:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1500/4871]    eta: 0:03:18  time: 0.0569  data_time: 0.0016  memory: 761  \n",
      "12/08 14:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1550/4871]    eta: 0:03:15  time: 0.0570  data_time: 0.0017  memory: 761  \n",
      "12/08 14:19:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1600/4871]    eta: 0:03:12  time: 0.0571  data_time: 0.0017  memory: 761  \n",
      "12/08 14:19:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1650/4871]    eta: 0:03:09  time: 0.0593  data_time: 0.0022  memory: 761  \n",
      "12/08 14:19:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1700/4871]    eta: 0:03:06  time: 0.0570  data_time: 0.0017  memory: 761  \n",
      "12/08 14:19:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1750/4871]    eta: 0:03:03  time: 0.0573  data_time: 0.0017  memory: 761  \n",
      "12/08 14:19:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1800/4871]    eta: 0:03:00  time: 0.0602  data_time: 0.0021  memory: 761  \n",
      "12/08 14:19:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1850/4871]    eta: 0:02:57  time: 0.0583  data_time: 0.0019  memory: 761  \n",
      "12/08 14:19:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1900/4871]    eta: 0:02:54  time: 0.0581  data_time: 0.0020  memory: 761  \n",
      "12/08 14:19:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1950/4871]    eta: 0:02:51  time: 0.0582  data_time: 0.0019  memory: 761  \n",
      "12/08 14:19:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2000/4871]    eta: 0:02:48  time: 0.0589  data_time: 0.0020  memory: 761  \n",
      "12/08 14:19:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2050/4871]    eta: 0:02:45  time: 0.0595  data_time: 0.0020  memory: 761  \n",
      "12/08 14:19:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2100/4871]    eta: 0:02:42  time: 0.0589  data_time: 0.0020  memory: 761  \n",
      "12/08 14:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2150/4871]    eta: 0:02:40  time: 0.0582  data_time: 0.0019  memory: 761  \n",
      "12/08 14:19:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2200/4871]    eta: 0:02:36  time: 0.0578  data_time: 0.0018  memory: 761  \n",
      "12/08 14:19:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2250/4871]    eta: 0:02:33  time: 0.0575  data_time: 0.0018  memory: 761  \n",
      "12/08 14:19:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2300/4871]    eta: 0:02:31  time: 0.0582  data_time: 0.0018  memory: 761  \n",
      "12/08 14:19:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2350/4871]    eta: 0:02:28  time: 0.0585  data_time: 0.0019  memory: 761  \n",
      "12/08 14:19:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2400/4871]    eta: 0:02:25  time: 0.0594  data_time: 0.0019  memory: 761  \n",
      "12/08 14:19:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2450/4871]    eta: 0:02:22  time: 0.0583  data_time: 0.0018  memory: 761  \n",
      "12/08 14:20:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2500/4871]    eta: 0:02:19  time: 0.0583  data_time: 0.0019  memory: 761  \n",
      "12/08 14:20:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2550/4871]    eta: 0:02:16  time: 0.0585  data_time: 0.0018  memory: 761  \n",
      "12/08 14:20:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2600/4871]    eta: 0:02:13  time: 0.0585  data_time: 0.0018  memory: 761  \n",
      "12/08 14:20:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2650/4871]    eta: 0:02:10  time: 0.0595  data_time: 0.0019  memory: 761  \n",
      "12/08 14:20:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2700/4871]    eta: 0:02:07  time: 0.0596  data_time: 0.0021  memory: 761  \n",
      "12/08 14:20:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2750/4871]    eta: 0:02:04  time: 0.0592  data_time: 0.0020  memory: 761  \n",
      "12/08 14:20:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2800/4871]    eta: 0:02:01  time: 0.0584  data_time: 0.0019  memory: 761  \n",
      "12/08 14:20:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2850/4871]    eta: 0:01:58  time: 0.0589  data_time: 0.0019  memory: 761  \n",
      "12/08 14:20:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2900/4871]    eta: 0:01:55  time: 0.0586  data_time: 0.0018  memory: 761  \n",
      "12/08 14:20:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2950/4871]    eta: 0:01:52  time: 0.0608  data_time: 0.0021  memory: 761  \n",
      "12/08 14:20:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3000/4871]    eta: 0:01:49  time: 0.0587  data_time: 0.0019  memory: 761  \n",
      "12/08 14:20:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3050/4871]    eta: 0:01:47  time: 0.0599  data_time: 0.0020  memory: 761  \n",
      "12/08 14:20:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3100/4871]    eta: 0:01:44  time: 0.0579  data_time: 0.0018  memory: 761  \n",
      "12/08 14:20:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3150/4871]    eta: 0:01:41  time: 0.0586  data_time: 0.0018  memory: 761  \n",
      "12/08 14:20:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3200/4871]    eta: 0:01:38  time: 0.0594  data_time: 0.0020  memory: 761  \n",
      "12/08 14:20:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3250/4871]    eta: 0:01:35  time: 0.0590  data_time: 0.0019  memory: 761  \n",
      "12/08 14:20:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3300/4871]    eta: 0:01:32  time: 0.0602  data_time: 0.0021  memory: 761  \n",
      "12/08 14:20:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3350/4871]    eta: 0:01:29  time: 0.0625  data_time: 0.0022  memory: 761  \n",
      "12/08 14:20:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3400/4871]    eta: 0:01:26  time: 0.0597  data_time: 0.0020  memory: 761  \n",
      "12/08 14:20:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3450/4871]    eta: 0:01:23  time: 0.0589  data_time: 0.0020  memory: 761  \n",
      "12/08 14:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3500/4871]    eta: 0:01:20  time: 0.0594  data_time: 0.0021  memory: 761  \n",
      "12/08 14:21:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3550/4871]    eta: 0:01:17  time: 0.0585  data_time: 0.0019  memory: 761  \n",
      "12/08 14:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3600/4871]    eta: 0:01:14  time: 0.0589  data_time: 0.0019  memory: 761  \n",
      "12/08 14:21:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3650/4871]    eta: 0:01:11  time: 0.0581  data_time: 0.0018  memory: 761  \n",
      "12/08 14:21:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3700/4871]    eta: 0:01:08  time: 0.0578  data_time: 0.0018  memory: 761  \n",
      "12/08 14:21:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3750/4871]    eta: 0:01:05  time: 0.0574  data_time: 0.0017  memory: 761  \n",
      "12/08 14:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3800/4871]    eta: 0:01:03  time: 0.0584  data_time: 0.0020  memory: 761  \n",
      "12/08 14:21:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3850/4871]    eta: 0:01:00  time: 0.0588  data_time: 0.0019  memory: 761  \n",
      "12/08 14:21:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3900/4871]    eta: 0:00:57  time: 0.0585  data_time: 0.0018  memory: 761  \n",
      "12/08 14:21:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3950/4871]    eta: 0:00:54  time: 0.0584  data_time: 0.0018  memory: 761  \n",
      "12/08 14:21:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4000/4871]    eta: 0:00:51  time: 0.0584  data_time: 0.0018  memory: 761  \n",
      "12/08 14:21:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4050/4871]    eta: 0:00:48  time: 0.0585  data_time: 0.0018  memory: 761  \n",
      "12/08 14:21:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4100/4871]    eta: 0:00:45  time: 0.0582  data_time: 0.0018  memory: 761  \n",
      "12/08 14:21:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4150/4871]    eta: 0:00:42  time: 0.0575  data_time: 0.0017  memory: 761  \n",
      "12/08 14:21:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4200/4871]    eta: 0:00:39  time: 0.0581  data_time: 0.0017  memory: 761  \n",
      "12/08 14:21:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4250/4871]    eta: 0:00:36  time: 0.0580  data_time: 0.0017  memory: 761  \n",
      "12/08 14:21:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4300/4871]    eta: 0:00:33  time: 0.0582  data_time: 0.0018  memory: 761  \n",
      "12/08 14:21:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4350/4871]    eta: 0:00:30  time: 0.0578  data_time: 0.0018  memory: 761  \n",
      "12/08 14:21:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4400/4871]    eta: 0:00:27  time: 0.0585  data_time: 0.0020  memory: 761  \n",
      "12/08 14:21:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4450/4871]    eta: 0:00:24  time: 0.0622  data_time: 0.0023  memory: 761  \n",
      "12/08 14:21:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4500/4871]    eta: 0:00:21  time: 0.0646  data_time: 0.0029  memory: 761  \n",
      "12/08 14:22:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4550/4871]    eta: 0:00:18  time: 0.0641  data_time: 0.0025  memory: 761  \n",
      "12/08 14:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4600/4871]    eta: 0:00:15  time: 0.0651  data_time: 0.0025  memory: 761  \n",
      "12/08 14:22:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4650/4871]    eta: 0:00:13  time: 0.0591  data_time: 0.0018  memory: 761  \n",
      "12/08 14:22:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4700/4871]    eta: 0:00:10  time: 0.0584  data_time: 0.0018  memory: 761  \n",
      "12/08 14:22:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4750/4871]    eta: 0:00:07  time: 0.0588  data_time: 0.0018  memory: 761  \n",
      "12/08 14:22:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4800/4871]    eta: 0:00:04  time: 0.0583  data_time: 0.0018  memory: 761  \n",
      "12/08 14:22:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4850/4871]    eta: 0:00:01  time: 0.0591  data_time: 0.0019  memory: 761  \n",
      "12/08 14:22:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - results are saved in /data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14\n",
      "12/08 14:22:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4871/4871]    data_time: 0.0019  time: 0.0590\n",
      "bbox json: /data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14/sparse_rcnn_r50_1024_stage_aug14_test.bbox.json\n",
      "Using sample csv: /data/ephemeral/home/model/sample_submission/faster_rcnn_mmdetection_submission.csv\n",
      "Saved submission: /data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14/sparse_rcnn_r50_1024_stage_aug14_submission_full.csv\n",
      "추론 완료\n",
      "제출 파일: /data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14/sparse_rcnn_r50_1024_stage_aug14_submission_full.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 이 셀은 학습이 끝난 후\n",
    "# work_dir에서 체크포인트를 찾아 test.json 전체에 대해 추론하고,\n",
    "# sample_submission 템플릿의 순서를 그대로 유지해 제출 csv를 생성합니다.\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmdet.utils import register_all_modules\n",
    "\n",
    "# 1) 샘플 csv를 선택하는 함수입니다.\n",
    "def pick_sample_csv(sample_dir: Path) -> Path:\n",
    "    csvs = sorted(sample_dir.glob(\"*.csv\"))\n",
    "    if not csvs:\n",
    "        raise FileNotFoundError(f\"샘플 제출 csv 없음: {sample_dir}\")\n",
    "    return csvs[0]\n",
    "\n",
    "# 2) 체크포인트를 찾는 함수입니다.\n",
    "def find_checkpoint(work_dir: Path) -> Optional[Path]:\n",
    "    last_txt = work_dir / \"last_checkpoint\"\n",
    "    if last_txt.exists():\n",
    "        p = last_txt.read_text().strip()\n",
    "        if p:\n",
    "            ck = Path(p)\n",
    "            if not ck.is_absolute():\n",
    "                ck = work_dir / ck\n",
    "            if ck.exists():\n",
    "                return ck\n",
    "\n",
    "    ckpts = sorted(work_dir.glob(\"*.pth\"))\n",
    "    if ckpts:\n",
    "        return ckpts[-1]\n",
    "    return None\n",
    "\n",
    "# 3) test.json에서 image_id와 file_name 매핑을 만듭니다.\n",
    "def parse_test_images(test_json: Path) -> Dict[int, str]:\n",
    "    with open(test_json, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return {img[\"id\"]: img[\"file_name\"] for img in data[\"images\"]}\n",
    "\n",
    "# 4) COCO bbox 결과 json을 PredictionString dict로 변환합니다.\n",
    "#    점수 임계값을 너무 낮게 두면 제출 파일이 과도하게 커질 수 있습니다.\n",
    "#    이전 제출 실패/용량 문제를 고려해 0.15를 기본으로 올려둡니다.\n",
    "def coco_bbox_json_to_prediction_dict(\n",
    "    bbox_json: Path,\n",
    "    test_json: Path,\n",
    "    score_thr: float = 0.15\n",
    ") -> Dict[str, str]:\n",
    "\n",
    "    id_to_fname = parse_test_images(test_json)\n",
    "\n",
    "    with open(bbox_json, \"r\") as f:\n",
    "        dets = json.load(f)\n",
    "\n",
    "    per_image = {}\n",
    "    for d in dets:\n",
    "        score = float(d.get(\"score\", 0.0))\n",
    "        if score < score_thr:\n",
    "            continue\n",
    "\n",
    "        img_id = int(d[\"image_id\"])\n",
    "        cat_id = int(d[\"category_id\"])\n",
    "\n",
    "        x, y, w, h = d[\"bbox\"]\n",
    "        x1, y1, x2, y2 = x, y, x + w, y + h\n",
    "\n",
    "        per_image.setdefault(img_id, []).append((cat_id, score, x1, y1, x2, y2))\n",
    "\n",
    "    pred_dict = {}\n",
    "    for img_id, fname in id_to_fname.items():\n",
    "        preds = sorted(per_image.get(img_id, []), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        tokens = []\n",
    "        for cat, sc, x1, y1, x2, y2 in preds:\n",
    "            tokens.extend([\n",
    "                str(cat),\n",
    "                f\"{sc:.6f}\",\n",
    "                f\"{x1:.1f}\",\n",
    "                f\"{y1:.1f}\",\n",
    "                f\"{x2:.1f}\",\n",
    "                f\"{y2:.1f}\",\n",
    "            ])\n",
    "\n",
    "        pred_dict[fname] = \" \".join(tokens)\n",
    "\n",
    "    return pred_dict\n",
    "\n",
    "# 5) 샘플 템플릿 순서를 고정해 저장합니다.\n",
    "def save_submission_with_sample(\n",
    "    pred_dict: Dict[str, str],\n",
    "    sample_csv_path: Path,\n",
    "    out_csv_path: Path\n",
    ") -> None:\n",
    "\n",
    "    sample = pd.read_csv(sample_csv_path)\n",
    "\n",
    "    # 샘플 컬럼 이름을 기준으로 안전 체크\n",
    "    if \"image_id\" not in sample.columns or \"PredictionString\" not in sample.columns:\n",
    "        raise ValueError(f\"샘플 컬럼이 예상과 다름: {list(sample.columns)}\")\n",
    "\n",
    "    # 샘플의 image_id 값은 파일명(file_name)과 동일한 형식이어야 합니다.\n",
    "    # pred_dict는 file_name 키로 구성되어 있으므로 그대로 매핑합니다.\n",
    "    sample[\"PredictionString\"] = sample[\"image_id\"].map(lambda x: pred_dict.get(x, \"\"))\n",
    "\n",
    "    out_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sample.to_csv(out_csv_path, index=False)\n",
    "\n",
    "    print(\"Saved submission:\", out_csv_path)\n",
    "\n",
    "# 6) 경로/실험 폴더를 지정합니다.\n",
    "MMD_ROOT = Path(\"/data/ephemeral/home/model/baseline/mmdetection\")\n",
    "WORK_DIR_ROOT = Path(\"/data/ephemeral/home/model/work_dirs_single\")\n",
    "EXP_WORK_DIR = WORK_DIR_ROOT / EXP_NAME\n",
    "\n",
    "assert EXP_WORK_DIR.exists(), f\"실험 폴더 없음: {EXP_WORK_DIR}\"\n",
    "\n",
    "# 7) 체크포인트를 찾습니다.\n",
    "ckpt = find_checkpoint(EXP_WORK_DIR)\n",
    "if ckpt is None:\n",
    "    raise FileNotFoundError(f\"checkpoint 없음: {EXP_WORK_DIR}\")\n",
    "\n",
    "print(\"checkpoint:\", ckpt)\n",
    "\n",
    "# 8) base cfg를 다시 로드합니다.\n",
    "#    학습과 동일 계열의 config를 쓰는 것이 안정적입니다.\n",
    "base_cfg_rel = \"configs/sparse_rcnn/sparse-rcnn_r50_fpn_300-proposals_crop-ms-480-800-3x_coco.py\"\n",
    "base_cfg_path = MMD_ROOT / base_cfg_rel\n",
    "assert base_cfg_path.exists(), f\"base cfg 없음: {base_cfg_path}\"\n",
    "\n",
    "register_all_modules(init_default_scope=True)\n",
    "\n",
    "test_cfg = Config.fromfile(str(base_cfg_path))\n",
    "test_cfg.default_scope = \"mmdet\"\n",
    "\n",
    "# 9) data_root 설정\n",
    "test_cfg.data_root = str(FULL_DATA_ROOT)\n",
    "\n",
    "# 10) test_dataloader 구성\n",
    "if \"test_dataloader\" not in test_cfg:\n",
    "    test_cfg.test_dataloader = test_cfg.val_dataloader\n",
    "\n",
    "loader = test_cfg.test_dataloader\n",
    "ds_cfg = loader.get(\"dataset\", loader)\n",
    "\n",
    "ds_cfg.metainfo = dict(classes=CLASSES)\n",
    "ds_cfg.data_root = str(FULL_DATA_ROOT)\n",
    "ds_cfg.ann_file = str(TEST_JSON)\n",
    "ds_cfg.data_prefix = dict(img=\"\")\n",
    "\n",
    "# 11) test pipeline은 단순/안정적으로 고정합니다.\n",
    "ds_cfg.pipeline = [\n",
    "    dict(type=\"LoadImageFromFile\"),\n",
    "    dict(type=\"Resize\", scale=IMAGE_SIZE, keep_ratio=True),\n",
    "    dict(type=\"PackDetInputs\"),\n",
    "]\n",
    "\n",
    "# 12) num_classes 수정\n",
    "def set_num_classes(node, num_classes: int):\n",
    "    if isinstance(node, dict):\n",
    "        if \"num_classes\" in node:\n",
    "            node[\"num_classes\"] = num_classes\n",
    "        for v in node.values():\n",
    "            set_num_classes(v, num_classes)\n",
    "    elif isinstance(node, list):\n",
    "        for v in node:\n",
    "            set_num_classes(v, num_classes)\n",
    "\n",
    "set_num_classes(test_cfg.model, len(CLASSES))\n",
    "\n",
    "# 13) 배치/워커\n",
    "test_cfg.test_dataloader.batch_size = 1\n",
    "test_cfg.test_dataloader.num_workers = 2\n",
    "\n",
    "# 14) evaluator 설정: COCO bbox json만 생성\n",
    "out_prefix = EXP_WORK_DIR / f\"{EXP_NAME}_test\"\n",
    "test_cfg.test_evaluator = dict(\n",
    "    type=\"CocoMetric\",\n",
    "    ann_file=str(TEST_JSON),\n",
    "    metric=\"bbox\",\n",
    "    format_only=True,\n",
    "    outfile_prefix=str(out_prefix),\n",
    ")\n",
    "\n",
    "# 15) 체크포인트 로드\n",
    "test_cfg.load_from = str(ckpt)\n",
    "\n",
    "# 16) 학습 관련 설정 제거\n",
    "test_cfg.train_dataloader = None\n",
    "test_cfg.train_cfg = None\n",
    "test_cfg.optim_wrapper = None\n",
    "if hasattr(test_cfg, \"param_scheduler\"):\n",
    "    test_cfg.param_scheduler = None\n",
    "if hasattr(test_cfg, \"val_dataloader\"):\n",
    "    test_cfg.val_dataloader = None\n",
    "if hasattr(test_cfg, \"val_cfg\"):\n",
    "    test_cfg.val_cfg = None\n",
    "if hasattr(test_cfg, \"val_evaluator\"):\n",
    "    test_cfg.val_evaluator = None\n",
    "\n",
    "# 17) work_dir 고정\n",
    "test_cfg.work_dir = str(EXP_WORK_DIR)\n",
    "\n",
    "# 18) Runner test 실행\n",
    "runner = Runner.from_cfg(test_cfg)\n",
    "runner.test()\n",
    "\n",
    "# 19) 생성된 bbox json 경로 찾기\n",
    "bbox_json = EXP_WORK_DIR / f\"{EXP_NAME}_test.bbox.json\"\n",
    "if not bbox_json.exists():\n",
    "    cand = sorted(EXP_WORK_DIR.glob(\"*_test.bbox.json\"))\n",
    "    if cand:\n",
    "        bbox_json = cand[-1]\n",
    "\n",
    "print(\"bbox json:\", bbox_json)\n",
    "if not bbox_json.exists():\n",
    "    raise FileNotFoundError(\"bbox json 생성 실패\")\n",
    "\n",
    "# 20) 제출 csv 생성\n",
    "sample_csv = pick_sample_csv(SAMPLE_SUB_DIR)\n",
    "print(\"Using sample csv:\", sample_csv)\n",
    "\n",
    "pred_dict = coco_bbox_json_to_prediction_dict(\n",
    "    bbox_json=bbox_json,\n",
    "    test_json=TEST_JSON,\n",
    "    score_thr=0.15  # 파일 용량/평가 실패 방지 목적\n",
    ")\n",
    "\n",
    "out_csv = EXP_WORK_DIR / f\"{EXP_NAME}_submission_full.csv\"\n",
    "save_submission_with_sample(pred_dict, sample_csv, out_csv)\n",
    "\n",
    "print(\"추론 완료\")\n",
    "print(\"제출 파일:\", out_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
