{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb48a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMD_ROOT: /data/ephemeral/home/model/baseline/mmdetection\n",
      "FULL_DATA_ROOT: /data/ephemeral/home/model/dataset\n",
      "TRAIN_JSON_FULL: /data/ephemeral/home/model/dataset/train.json\n",
      "TEST_JSON_FULL : /data/ephemeral/home/model/dataset/test.json\n",
      "SAMPLE_SUB_DIR : /data/ephemeral/home/model/sample_submission\n",
      "WORK_DIR_ROOT  : /data/ephemeral/home/model/baseline/ensemble copy/work_dirs\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ipynb 공통 유틸: 경로, split 생성, config 안전 패치\n",
    "\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmdet.utils import register_all_modules\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 1) 고정 경로 (네 환경 기준)\n",
    "# -----------------------\n",
    "\n",
    "# mmdetection 루트 (configs 탐색용)\n",
    "MMD_ROOT = Path(\"/data/ephemeral/home/model/baseline/mmdetection\")\n",
    "\n",
    "# 데이터 루트\n",
    "FULL_DATA_ROOT = Path(\"/data/ephemeral/home/model/dataset\")\n",
    "TRAIN_JSON_FULL = FULL_DATA_ROOT / \"train.json\"\n",
    "TEST_JSON_FULL  = FULL_DATA_ROOT / \"test.json\"\n",
    "\n",
    "# 샘플 제출 폴더\n",
    "SAMPLE_SUB_DIR = Path(\"/data/ephemeral/home/model/sample_submission\")\n",
    "\n",
    "# 단일 모델 실험 산출물 저장 위치\n",
    "WORK_DIR_ROOT = Path(\"/data/ephemeral/home/model/baseline/ensemble copy/work_dirs\")\n",
    "\n",
    "WORK_DIR_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 이미지 스케일 고정\n",
    "IMAGE_SCALE = (1024, 1024)\n",
    "\n",
    "# 클래스 10개 (대회 공지 기준 순서)\n",
    "CLASSES = (\n",
    "    \"General trash\",\n",
    "    \"Paper\",\n",
    "    \"Paper pack\",\n",
    "    \"Metal\",\n",
    "    \"Glass\",\n",
    "    \"Plastic\",\n",
    "    \"Styrofoam\",\n",
    "    \"Plastic bag\",\n",
    "    \"Battery\",\n",
    "    \"Clothing\",\n",
    ")\n",
    "\n",
    "# split 설정\n",
    "RANDOM_SEED = 42\n",
    "TRAIN_RATIO = 0.9   # 0.8/0.2보다 학습 데이터를 늘려 단일 모델 성능 안정성을 노림\n",
    "\n",
    "\n",
    "print(\"MMD_ROOT:\", MMD_ROOT)\n",
    "print(\"FULL_DATA_ROOT:\", FULL_DATA_ROOT)\n",
    "print(\"TRAIN_JSON_FULL:\", TRAIN_JSON_FULL)\n",
    "print(\"TEST_JSON_FULL :\", TEST_JSON_FULL)\n",
    "print(\"SAMPLE_SUB_DIR :\", SAMPLE_SUB_DIR)\n",
    "print(\"WORK_DIR_ROOT  :\", WORK_DIR_ROOT)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2) COCO json 로드/저장\n",
    "# -----------------------\n",
    "\n",
    "def load_coco(json_path: Path) -> Dict:\n",
    "    with open(json_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_coco(data: Dict, json_path: Path) -> None:\n",
    "    json_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 3) train/val split 생성\n",
    "# -----------------------\n",
    "\n",
    "def make_train_val_split(\n",
    "    src_json: Path,\n",
    "    out_dir: Path,\n",
    "    train_ratio: float = 0.9,\n",
    "    seed: int = 42\n",
    ") -> Dict[str, Path]:\n",
    "    \"\"\"\n",
    "    이미지 id 기준 랜덤 분할.\n",
    "    detection에서 가장 기본적이고 안전한 방식.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    data = load_coco(src_json)\n",
    "    images = data[\"images\"]\n",
    "    anns = data[\"annotations\"]\n",
    "\n",
    "    img_ids = [img[\"id\"] for img in images]\n",
    "    random.shuffle(img_ids)\n",
    "\n",
    "    split_idx = int(len(img_ids) * train_ratio)\n",
    "    train_ids = set(img_ids[:split_idx])\n",
    "    val_ids   = set(img_ids[split_idx:])\n",
    "\n",
    "    def _filter(ids: set):\n",
    "        # ids에 해당하는 image만 남김\n",
    "        imgs = [img for img in images if img[\"id\"] in ids]\n",
    "        img_set = {img[\"id\"] for img in imgs}\n",
    "        # 해당 이미지에 매칭되는 annotation만 남김\n",
    "        filtered_anns = [ann for ann in anns if ann[\"image_id\"] in img_set]\n",
    "        return {**data, \"images\": imgs, \"annotations\": filtered_anns}\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    train_json = out_dir / \"train_split.json\"\n",
    "    val_json   = out_dir / \"val_split.json\"\n",
    "\n",
    "    save_coco(_filter(train_ids), train_json)\n",
    "    save_coco(_filter(val_ids), val_json)\n",
    "\n",
    "    return {\"train\": train_json, \"val\": val_json}\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 4) pipeline 스케일 고정\n",
    "# -----------------------\n",
    "\n",
    "def set_img_scale(pipeline, scale):\n",
    "    \"\"\"\n",
    "    Resize / RandomResize / RandomChoiceResize 등을 1024로 통일.\n",
    "    \"\"\"\n",
    "    for t in pipeline:\n",
    "        if isinstance(t, list):\n",
    "            set_img_scale(t, scale)\n",
    "            continue\n",
    "        if not isinstance(t, dict):\n",
    "            continue\n",
    "\n",
    "        if t.get(\"type\") in (\"Resize\", \"RandomResize\", \"RandomChoiceResize\"):\n",
    "            if \"scale\" in t:\n",
    "                t[\"scale\"] = scale\n",
    "            if \"img_scale\" in t:\n",
    "                t[\"img_scale\"] = scale\n",
    "            if \"scales\" in t:\n",
    "                t[\"scales\"] = [scale]\n",
    "\n",
    "        if \"transforms\" in t:\n",
    "            set_img_scale(t[\"transforms\"], scale)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 5) num_classes 재귀 고정\n",
    "# -----------------------\n",
    "\n",
    "def set_num_classes(model_cfg, num_classes: int):\n",
    "    \"\"\"\n",
    "    다양한 head 구조에서 num_classes를 재귀적으로 10으로 맞춤.\n",
    "    \"\"\"\n",
    "    if isinstance(model_cfg, dict):\n",
    "        if \"num_classes\" in model_cfg:\n",
    "            model_cfg[\"num_classes\"] = num_classes\n",
    "        for v in model_cfg.values():\n",
    "            set_num_classes(v, num_classes)\n",
    "    elif isinstance(model_cfg, list):\n",
    "        for v in model_cfg:\n",
    "            set_num_classes(v, num_classes)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 6) 샘플 csv 자동 선택\n",
    "# -----------------------\n",
    "\n",
    "def pick_sample_csv(sample_dir: Path) -> Path:\n",
    "    \"\"\"\n",
    "    - 이름에 mmdetection 포함된 샘플을 우선\n",
    "    - 없으면 첫 번째 csv\n",
    "    \"\"\"\n",
    "    csvs = sorted(sample_dir.glob(\"*.csv\"))\n",
    "    if not csvs:\n",
    "        raise FileNotFoundError(f\"샘플 제출 csv가 없습니다: {sample_dir}\")\n",
    "\n",
    "    for c in csvs:\n",
    "        if \"mmdetection\" in c.name.lower():\n",
    "            return c\n",
    "\n",
    "    return csvs[0]\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 7) base config 자동 탐색\n",
    "# -----------------------\n",
    "\n",
    "def pick_best_single_base_cfg() -> Path:\n",
    "    \"\"\"\n",
    "    앙상블에 없던 단일 후보로 RTMDet 계열을 우선 시도.\n",
    "    환경에 따라 config 파일명이 다를 수 있어\n",
    "    여러 후보 중 '존재하는 첫 번째'를 선택.\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        \"configs/rtmdet/rtmdet_l_8xb32-300e_coco.py\",\n",
    "        \"configs/rtmdet/rtmdet_m_8xb32-300e_coco.py\",\n",
    "        \"configs/rtmdet/rtmdet_s_8xb32-300e_coco.py\",\n",
    "        # 혹시 RTMDet가 없다면 2순위 후보\n",
    "        \"configs/yolox/yolox_l_8xb8-300e_coco.py\",\n",
    "        \"configs/yolox/yolox_m_8xb8-300e_coco.py\",\n",
    "    ]\n",
    "\n",
    "    for rel in candidates:\n",
    "        p = MMD_ROOT / rel\n",
    "        if p.exists():\n",
    "            print(\"Selected base cfg:\", p)\n",
    "            return p\n",
    "\n",
    "    # 마지막 안전장치: 그래도 없으면 에러로 명확히 알려줌\n",
    "    raise FileNotFoundError(\n",
    "        \"RTMDet/YOLOX 후보 config를 찾지 못했습니다. \"\n",
    "        \"MMD_ROOT/configs 아래 실제 파일명을 확인해 주세요.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f369583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample csv: /data/ephemeral/home/model/sample_submission/faster_rcnn_mmdetection_submission.csv\n",
      "checkpoint: /data/ephemeral/home/model/work_dirs_single/rtmdet_1024_single/epoch_12.pth\n",
      "Using base cfg: /data/ephemeral/home/model/baseline/mmdetection/configs/rtmdet/rtmdet_l_8xb32-300e_coco.py\n",
      "12/07 16:20:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 47184910\n",
      "    GPU 0: Tesla V100-SXM2-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu121\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 47184910\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: gcc: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/07 16:20:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "base_lr = 0.004\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        ema_type='ExpMomentumEMA',\n",
      "        momentum=0.0002,\n",
      "        priority=49,\n",
      "        type='EMAHook',\n",
      "        update_buffers=True),\n",
      "    dict(\n",
      "        switch_epoch=280,\n",
      "        switch_pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.1,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(crop_size=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='RandomCrop'),\n",
      "            dict(type='YOLOXHSVRandomAug'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='PipelineSwitchHook'),\n",
      "]\n",
      "data_root = '/data/ephemeral/home/model/dataset'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=10, max_keep_ckpts=3, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_scales = [\n",
      "    (\n",
      "        640,\n",
      "        640,\n",
      "    ),\n",
      "    (\n",
      "        320,\n",
      "        320,\n",
      "    ),\n",
      "    (\n",
      "        960,\n",
      "        960,\n",
      "    ),\n",
      "]\n",
      "interval = 10\n",
      "load_from = '/data/ephemeral/home/model/work_dirs_single/rtmdet_1024_single/epoch_12.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 300\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        arch='P5',\n",
      "        channel_attention=True,\n",
      "        deepen_factor=1,\n",
      "        expand_ratio=0.5,\n",
      "        norm_cfg=dict(type='SyncBN'),\n",
      "        type='CSPNeXt',\n",
      "        widen_factor=1),\n",
      "    bbox_head=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        anchor_generator=dict(\n",
      "            offset=0, strides=[\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ], type='MlvlPointGenerator'),\n",
      "        bbox_coder=dict(type='DistancePointBBoxCoder'),\n",
      "        exp_on_reg=True,\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "        loss_cls=dict(\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0,\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        norm_cfg=dict(type='SyncBN'),\n",
      "        num_classes=10,\n",
      "        pred_kernel_size=1,\n",
      "        share_conv=True,\n",
      "        stacked_convs=2,\n",
      "        type='RTMDetSepBNHead',\n",
      "        with_objectness=False),\n",
      "    data_preprocessor=dict(\n",
      "        batch_augments=None,\n",
      "        bgr_to_rgb=False,\n",
      "        mean=[\n",
      "            103.53,\n",
      "            116.28,\n",
      "            123.675,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.12,\n",
      "            58.395,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        expand_ratio=0.5,\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "        ],\n",
      "        norm_cfg=dict(type='SyncBN'),\n",
      "        num_csp_blocks=3,\n",
      "        out_channels=256,\n",
      "        type='CSPNeXtPAFPN'),\n",
      "    test_cfg=dict(\n",
      "        max_per_img=300,\n",
      "        min_bbox_size=0,\n",
      "        nms=dict(iou_threshold=0.65, type='nms'),\n",
      "        nms_pre=30000,\n",
      "        score_thr=0.001),\n",
      "    train_cfg=dict(\n",
      "        allowed_border=-1,\n",
      "        assigner=dict(topk=13, type='DynamicSoftLabelAssigner'),\n",
      "        debug=False,\n",
      "        pos_weight=-1),\n",
      "    type='RTMDet')\n",
      "optim_wrapper = None\n",
      "param_scheduler = None\n",
      "resume = False\n",
      "stage2_num_epochs = 20\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='/data/ephemeral/home/model/dataset/test.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='/data/ephemeral/home/model/dataset',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='/data/ephemeral/home/model/dataset/test.json',\n",
      "    format_only=True,\n",
      "    metric='bbox',\n",
      "    outfile_prefix=\n",
      "    '/data/ephemeral/home/model/work_dirs_single/rtmdet_1024_single/rtmdet_1024_single_test',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Resize'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Pad'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = None\n",
      "train_dataloader = None\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(img_scale=(\n",
      "        640,\n",
      "        640,\n",
      "    ), pad_val=114.0, type='CachedMosaic'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.1,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            1280,\n",
      "            1280,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(crop_size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(type='YOLOXHSVRandomAug'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Pad'),\n",
      "    dict(\n",
      "        img_scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        max_cached_images=20,\n",
      "        pad_val=(\n",
      "            114,\n",
      "            114,\n",
      "            114,\n",
      "        ),\n",
      "        ratio_range=(\n",
      "            1.0,\n",
      "            1.0,\n",
      "        ),\n",
      "        type='CachedMixUp'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "train_pipeline_stage2 = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.1,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(crop_size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(type='YOLOXHSVRandomAug'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Pad'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "tta_model = dict(\n",
      "    tta_cfg=dict(max_per_img=100, nms=dict(iou_threshold=0.6, type='nms')),\n",
      "    type='DetTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ), type='Resize'),\n",
      "                dict(keep_ratio=True, scale=(\n",
      "                    320,\n",
      "                    320,\n",
      "                ), type='Resize'),\n",
      "                dict(keep_ratio=True, scale=(\n",
      "                    960,\n",
      "                    960,\n",
      "                ), type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(prob=1.0, type='RandomFlip'),\n",
      "                dict(prob=0.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    pad_val=dict(img=(\n",
      "                        114,\n",
      "                        114,\n",
      "                        114,\n",
      "                    )),\n",
      "                    size=(\n",
      "                        960,\n",
      "                        960,\n",
      "                    ),\n",
      "                    type='Pad'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    meta_keys=(\n",
      "                        'img_id',\n",
      "                        'img_path',\n",
      "                        'ori_shape',\n",
      "                        'img_shape',\n",
      "                        'scale_factor',\n",
      "                        'flip',\n",
      "                        'flip_direction',\n",
      "                    ),\n",
      "                    type='PackDetInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = None\n",
      "val_dataloader = None\n",
      "val_evaluator = None\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/data/ephemeral/home/model/work_dirs_single/rtmdet_1024_single'\n",
      "\n",
      "12/07 16:20:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "12/07 16:20:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_load_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(NORMAL      ) PipelineSwitchHook                 \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_save_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loads checkpoint by local backend from path: /data/ephemeral/home/model/work_dirs_single/rtmdet_1024_single/epoch_12.pth\n",
      "12/07 16:20:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /data/ephemeral/home/model/work_dirs_single/rtmdet_1024_single/epoch_12.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/07 16:20:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [  50/4871]    eta: 0:11:14  time: 0.1400  data_time: 0.0066  memory: 734  \n",
      "12/07 16:21:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 100/4871]    eta: 0:09:29  time: 0.0990  data_time: 0.0025  memory: 734  \n",
      "12/07 16:21:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 150/4871]    eta: 0:08:53  time: 0.1001  data_time: 0.0025  memory: 734  \n",
      "12/07 16:21:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 200/4871]    eta: 0:08:30  time: 0.0985  data_time: 0.0025  memory: 734  \n",
      "12/07 16:21:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 250/4871]    eta: 0:08:16  time: 0.0998  data_time: 0.0027  memory: 734  \n",
      "12/07 16:21:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 300/4871]    eta: 0:08:05  time: 0.1001  data_time: 0.0026  memory: 734  \n",
      "12/07 16:21:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 350/4871]    eta: 0:07:56  time: 0.1005  data_time: 0.0030  memory: 734  \n",
      "12/07 16:21:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 400/4871]    eta: 0:07:44  time: 0.0929  data_time: 0.0025  memory: 734  \n",
      "12/07 16:21:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 450/4871]    eta: 0:07:17  time: 0.0598  data_time: 0.0019  memory: 734  \n",
      "12/07 16:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 500/4871]    eta: 0:07:04  time: 0.0806  data_time: 0.0019  memory: 734  \n",
      "12/07 16:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 550/4871]    eta: 0:07:07  time: 0.1164  data_time: 0.0022  memory: 734  \n",
      "12/07 16:21:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 600/4871]    eta: 0:07:11  time: 0.1235  data_time: 0.0026  memory: 734  \n",
      "12/07 16:21:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 650/4871]    eta: 0:07:11  time: 0.1174  data_time: 0.0023  memory: 734  \n",
      "12/07 16:22:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 700/4871]    eta: 0:07:09  time: 0.1143  data_time: 0.0020  memory: 734  \n",
      "12/07 16:22:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 750/4871]    eta: 0:07:07  time: 0.1128  data_time: 0.0020  memory: 734  \n",
      "12/07 16:22:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 800/4871]    eta: 0:07:05  time: 0.1177  data_time: 0.0024  memory: 734  \n",
      "12/07 16:22:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 850/4871]    eta: 0:07:02  time: 0.1137  data_time: 0.0020  memory: 734  \n",
      "12/07 16:22:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 900/4871]    eta: 0:07:00  time: 0.1198  data_time: 0.0027  memory: 734  \n",
      "12/07 16:22:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 950/4871]    eta: 0:06:58  time: 0.1194  data_time: 0.0024  memory: 734  \n",
      "12/07 16:22:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1000/4871]    eta: 0:06:54  time: 0.1149  data_time: 0.0022  memory: 734  \n",
      "12/07 16:22:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1050/4871]    eta: 0:06:50  time: 0.1127  data_time: 0.0021  memory: 734  \n",
      "12/07 16:22:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1100/4871]    eta: 0:06:46  time: 0.1149  data_time: 0.0022  memory: 734  \n",
      "12/07 16:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1150/4871]    eta: 0:06:41  time: 0.1141  data_time: 0.0021  memory: 734  \n",
      "12/07 16:23:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1200/4871]    eta: 0:06:37  time: 0.1130  data_time: 0.0022  memory: 734  \n",
      "12/07 16:23:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1250/4871]    eta: 0:06:32  time: 0.1116  data_time: 0.0021  memory: 734  \n",
      "12/07 16:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1300/4871]    eta: 0:06:27  time: 0.1136  data_time: 0.0021  memory: 734  \n",
      "12/07 16:23:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1350/4871]    eta: 0:06:22  time: 0.1134  data_time: 0.0024  memory: 734  \n",
      "12/07 16:23:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1400/4871]    eta: 0:06:17  time: 0.1145  data_time: 0.0025  memory: 734  \n",
      "12/07 16:23:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1450/4871]    eta: 0:06:13  time: 0.1141  data_time: 0.0022  memory: 734  \n",
      "12/07 16:23:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1500/4871]    eta: 0:06:08  time: 0.1170  data_time: 0.0024  memory: 734  \n",
      "12/07 16:23:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1550/4871]    eta: 0:06:04  time: 0.1178  data_time: 0.0022  memory: 734  \n",
      "12/07 16:23:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1600/4871]    eta: 0:05:59  time: 0.1151  data_time: 0.0022  memory: 734  \n",
      "12/07 16:23:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1650/4871]    eta: 0:05:54  time: 0.1170  data_time: 0.0021  memory: 734  \n",
      "12/07 16:23:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1700/4871]    eta: 0:05:49  time: 0.1123  data_time: 0.0020  memory: 734  \n",
      "12/07 16:24:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1750/4871]    eta: 0:05:43  time: 0.1043  data_time: 0.0019  memory: 734  \n",
      "12/07 16:24:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1800/4871]    eta: 0:05:33  time: 0.0639  data_time: 0.0020  memory: 734  \n",
      "12/07 16:24:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1850/4871]    eta: 0:05:27  time: 0.1016  data_time: 0.0024  memory: 734  \n",
      "12/07 16:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1900/4871]    eta: 0:05:21  time: 0.1000  data_time: 0.0025  memory: 734  \n",
      "12/07 16:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1950/4871]    eta: 0:05:15  time: 0.0984  data_time: 0.0023  memory: 734  \n",
      "12/07 16:24:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2000/4871]    eta: 0:05:09  time: 0.0981  data_time: 0.0025  memory: 734  \n",
      "12/07 16:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2050/4871]    eta: 0:05:03  time: 0.1000  data_time: 0.0026  memory: 734  \n",
      "12/07 16:24:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2100/4871]    eta: 0:04:57  time: 0.0997  data_time: 0.0026  memory: 734  \n",
      "12/07 16:24:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2150/4871]    eta: 0:04:51  time: 0.0965  data_time: 0.0026  memory: 734  \n",
      "12/07 16:24:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2200/4871]    eta: 0:04:45  time: 0.0977  data_time: 0.0027  memory: 734  \n",
      "12/07 16:24:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2250/4871]    eta: 0:04:39  time: 0.0920  data_time: 0.0022  memory: 734  \n",
      "12/07 16:24:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2300/4871]    eta: 0:04:31  time: 0.0601  data_time: 0.0021  memory: 734  \n",
      "12/07 16:24:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2350/4871]    eta: 0:04:24  time: 0.0799  data_time: 0.0020  memory: 734  \n",
      "12/07 16:25:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2400/4871]    eta: 0:04:20  time: 0.1200  data_time: 0.0021  memory: 734  \n",
      "12/07 16:25:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2450/4871]    eta: 0:04:15  time: 0.1141  data_time: 0.0023  memory: 734  \n",
      "12/07 16:25:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2500/4871]    eta: 0:04:10  time: 0.1157  data_time: 0.0018  memory: 734  \n",
      "12/07 16:25:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2550/4871]    eta: 0:04:05  time: 0.1115  data_time: 0.0020  memory: 734  \n",
      "12/07 16:25:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2600/4871]    eta: 0:04:00  time: 0.1151  data_time: 0.0020  memory: 734  \n",
      "12/07 16:25:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2650/4871]    eta: 0:03:55  time: 0.1167  data_time: 0.0021  memory: 734  \n",
      "12/07 16:25:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2700/4871]    eta: 0:03:50  time: 0.1166  data_time: 0.0025  memory: 734  \n",
      "12/07 16:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2750/4871]    eta: 0:03:45  time: 0.1102  data_time: 0.0021  memory: 734  \n",
      "12/07 16:25:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2800/4871]    eta: 0:03:40  time: 0.1174  data_time: 0.0023  memory: 734  \n",
      "12/07 16:25:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2850/4871]    eta: 0:03:35  time: 0.1172  data_time: 0.0021  memory: 734  \n",
      "12/07 16:26:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2900/4871]    eta: 0:03:30  time: 0.1157  data_time: 0.0020  memory: 734  \n",
      "12/07 16:26:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2950/4871]    eta: 0:03:25  time: 0.1196  data_time: 0.0024  memory: 734  \n",
      "12/07 16:26:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3000/4871]    eta: 0:03:20  time: 0.1123  data_time: 0.0024  memory: 734  \n",
      "12/07 16:26:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3050/4871]    eta: 0:03:15  time: 0.1166  data_time: 0.0022  memory: 734  \n",
      "12/07 16:26:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3100/4871]    eta: 0:03:10  time: 0.1171  data_time: 0.0022  memory: 734  \n",
      "12/07 16:26:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3150/4871]    eta: 0:03:05  time: 0.1162  data_time: 0.0021  memory: 734  \n",
      "12/07 16:26:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3200/4871]    eta: 0:03:00  time: 0.1172  data_time: 0.0021  memory: 734  \n",
      "12/07 16:26:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3250/4871]    eta: 0:02:55  time: 0.1146  data_time: 0.0022  memory: 734  \n",
      "12/07 16:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3300/4871]    eta: 0:02:49  time: 0.1147  data_time: 0.0021  memory: 734  \n",
      "12/07 16:26:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3350/4871]    eta: 0:02:44  time: 0.1138  data_time: 0.0019  memory: 734  \n",
      "12/07 16:26:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3400/4871]    eta: 0:02:39  time: 0.1172  data_time: 0.0021  memory: 734  \n",
      "12/07 16:27:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3450/4871]    eta: 0:02:33  time: 0.1116  data_time: 0.0020  memory: 734  \n",
      "12/07 16:27:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3500/4871]    eta: 0:02:28  time: 0.1171  data_time: 0.0021  memory: 734  \n",
      "12/07 16:27:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3550/4871]    eta: 0:02:23  time: 0.1159  data_time: 0.0020  memory: 734  \n",
      "12/07 16:27:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3600/4871]    eta: 0:02:17  time: 0.0940  data_time: 0.0019  memory: 734  \n",
      "12/07 16:27:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3650/4871]    eta: 0:02:11  time: 0.0773  data_time: 0.0023  memory: 734  \n",
      "12/07 16:27:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3700/4871]    eta: 0:02:06  time: 0.1010  data_time: 0.0027  memory: 734  \n",
      "12/07 16:27:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3750/4871]    eta: 0:02:00  time: 0.0991  data_time: 0.0021  memory: 734  \n",
      "12/07 16:27:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3800/4871]    eta: 0:01:55  time: 0.0997  data_time: 0.0028  memory: 734  \n",
      "12/07 16:27:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3850/4871]    eta: 0:01:49  time: 0.1018  data_time: 0.0026  memory: 734  \n",
      "12/07 16:27:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3900/4871]    eta: 0:01:44  time: 0.0995  data_time: 0.0025  memory: 734  \n",
      "12/07 16:27:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3950/4871]    eta: 0:01:38  time: 0.1015  data_time: 0.0023  memory: 734  \n",
      "12/07 16:28:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4000/4871]    eta: 0:01:33  time: 0.0996  data_time: 0.0027  memory: 734  \n",
      "12/07 16:28:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4050/4871]    eta: 0:01:27  time: 0.0995  data_time: 0.0021  memory: 734  \n",
      "12/07 16:28:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4100/4871]    eta: 0:01:22  time: 0.0733  data_time: 0.0022  memory: 734  \n",
      "12/07 16:28:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4150/4871]    eta: 0:01:16  time: 0.0595  data_time: 0.0017  memory: 734  \n",
      "12/07 16:28:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4200/4871]    eta: 0:01:11  time: 0.0963  data_time: 0.0020  memory: 734  \n",
      "12/07 16:28:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4250/4871]    eta: 0:01:05  time: 0.1179  data_time: 0.0024  memory: 734  \n",
      "12/07 16:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4300/4871]    eta: 0:01:00  time: 0.1176  data_time: 0.0021  memory: 734  \n",
      "12/07 16:28:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4350/4871]    eta: 0:00:55  time: 0.1220  data_time: 0.0021  memory: 734  \n",
      "12/07 16:28:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4400/4871]    eta: 0:00:50  time: 0.1163  data_time: 0.0023  memory: 734  \n",
      "12/07 16:28:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4450/4871]    eta: 0:00:44  time: 0.1130  data_time: 0.0025  memory: 734  \n",
      "12/07 16:28:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4500/4871]    eta: 0:00:39  time: 0.1165  data_time: 0.0024  memory: 734  \n",
      "12/07 16:28:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4550/4871]    eta: 0:00:34  time: 0.1170  data_time: 0.0025  memory: 734  \n",
      "12/07 16:29:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4600/4871]    eta: 0:00:29  time: 0.1175  data_time: 0.0024  memory: 734  \n",
      "12/07 16:29:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4650/4871]    eta: 0:00:23  time: 0.1153  data_time: 0.0020  memory: 734  \n",
      "12/07 16:29:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4700/4871]    eta: 0:00:18  time: 0.1161  data_time: 0.0020  memory: 734  \n",
      "12/07 16:29:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4750/4871]    eta: 0:00:12  time: 0.1182  data_time: 0.0028  memory: 734  \n",
      "12/07 16:29:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4800/4871]    eta: 0:00:07  time: 0.1172  data_time: 0.0022  memory: 734  \n",
      "12/07 16:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4850/4871]    eta: 0:00:02  time: 0.1154  data_time: 0.0022  memory: 734  \n",
      "12/07 16:30:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - results are saved in /data/ephemeral/home/model/work_dirs_single/rtmdet_1024_single\n",
      "12/07 16:30:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4871/4871]    data_time: 0.0023  time: 0.1076\n",
      "bbox json: /data/ephemeral/home/model/work_dirs_single/rtmdet_1024_single/rtmdet_1024_single_test.bbox.json\n",
      "Saved submission: /data/ephemeral/home/model/work_dirs_single/rtmdet_1024_single/rtmdet_1024_single_submission_full.csv\n",
      "단일 모델 전체 테스트 추론 완료\n",
      "제출 파일: /data/ephemeral/home/model/work_dirs_single/rtmdet_1024_single/rtmdet_1024_single_submission_full.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# RTMDet 단일 모델 전체 테스트 추론 (ipynb 단독 실행 안전 버전)\n",
    "# - test.json 전체 대상으로 COCO bbox json 생성\n",
    "# - 샘플 템플릿 고정 방식으로 submission 생성\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmdet.utils import register_all_modules\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 0) 경로/상수 (학습 로그 기준으로 정확히 맞춤)\n",
    "# -----------------------\n",
    "\n",
    "MMD_ROOT = Path(\"/data/ephemeral/home/model/baseline/mmdetection\")\n",
    "\n",
    "FULL_DATA_ROOT = Path(\"/data/ephemeral/home/model/dataset\")\n",
    "TEST_JSON_FULL  = FULL_DATA_ROOT / \"test.json\"\n",
    "\n",
    "SAMPLE_SUB_DIR  = Path(\"/data/ephemeral/home/model/sample_submission\")\n",
    "\n",
    "# 중요: 네 학습 로그의 Final work_dir 기준\n",
    "WORK_DIR_ROOT = Path(\"/data/ephemeral/home/model/work_dirs_single\")\n",
    "EXP_NAME = \"rtmdet_1024_single\"\n",
    "\n",
    "EXP_WORK_DIR = WORK_DIR_ROOT / EXP_NAME\n",
    "\n",
    "IMAGE_SCALE = (1024, 1024)\n",
    "\n",
    "CLASSES = (\n",
    "    \"General trash\",\n",
    "    \"Paper\",\n",
    "    \"Paper pack\",\n",
    "    \"Metal\",\n",
    "    \"Glass\",\n",
    "    \"Plastic\",\n",
    "    \"Styrofoam\",\n",
    "    \"Plastic bag\",\n",
    "    \"Battery\",\n",
    "    \"Clothing\",\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 1) 유틸 함수들\n",
    "# -----------------------\n",
    "\n",
    "def pick_sample_csv(sample_dir: Path) -> Path:\n",
    "    csvs = sorted(sample_dir.glob(\"*.csv\"))\n",
    "    if not csvs:\n",
    "        raise FileNotFoundError(f\"샘플 제출 csv 없음: {sample_dir}\")\n",
    "    for c in csvs:\n",
    "        if \"mmdetection\" in c.name.lower():\n",
    "            return c\n",
    "    return csvs[0]\n",
    "\n",
    "\n",
    "def set_img_scale(pipeline, scale):\n",
    "    for t in pipeline:\n",
    "        if isinstance(t, list):\n",
    "            set_img_scale(t, scale)\n",
    "            continue\n",
    "        if not isinstance(t, dict):\n",
    "            continue\n",
    "\n",
    "        if t.get(\"type\") in (\"Resize\", \"RandomResize\", \"RandomChoiceResize\"):\n",
    "            if \"scale\" in t:\n",
    "                t[\"scale\"] = scale\n",
    "            if \"img_scale\" in t:\n",
    "                t[\"img_scale\"] = scale\n",
    "            if \"scales\" in t:\n",
    "                t[\"scales\"] = [scale]\n",
    "\n",
    "        if \"transforms\" in t:\n",
    "            set_img_scale(t[\"transforms\"], scale)\n",
    "\n",
    "\n",
    "def set_num_classes(model_cfg, num_classes: int):\n",
    "    if isinstance(model_cfg, dict):\n",
    "        if \"num_classes\" in model_cfg:\n",
    "            model_cfg[\"num_classes\"] = num_classes\n",
    "        for v in model_cfg.values():\n",
    "            set_num_classes(v, num_classes)\n",
    "    elif isinstance(model_cfg, list):\n",
    "        for v in model_cfg:\n",
    "            set_num_classes(v, num_classes)\n",
    "\n",
    "\n",
    "def find_checkpoint(work_dir: Path) -> Optional[Path]:\n",
    "    # 1) last_checkpoint 우선\n",
    "    last_txt = work_dir / \"last_checkpoint\"\n",
    "    if last_txt.exists():\n",
    "        p = last_txt.read_text().strip()\n",
    "        if p:\n",
    "            ck = Path(p)\n",
    "            # 상대경로일 수 있어 보정\n",
    "            if not ck.is_absolute():\n",
    "                ck = work_dir / ck\n",
    "            if ck.exists():\n",
    "                return ck\n",
    "\n",
    "    # 2) 없으면 최신 *.pth\n",
    "    ckpts = sorted(work_dir.glob(\"*.pth\"))\n",
    "    if ckpts:\n",
    "        return ckpts[-1]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_test_images(test_json: Path) -> Dict[int, str]:\n",
    "    with open(test_json, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return {img[\"id\"]: img[\"file_name\"] for img in data[\"images\"]}\n",
    "\n",
    "\n",
    "def coco_bbox_json_to_prediction_dict(\n",
    "    bbox_json: Path,\n",
    "    test_json: Path,\n",
    "    score_thr: float = 0.05\n",
    ") -> Dict[str, str]:\n",
    "\n",
    "    id_to_fname = parse_test_images(test_json)\n",
    "\n",
    "    with open(bbox_json, \"r\") as f:\n",
    "        dets = json.load(f)\n",
    "\n",
    "    per_image = {}\n",
    "    for d in dets:\n",
    "        score = float(d.get(\"score\", 0.0))\n",
    "        if score < score_thr:\n",
    "            continue\n",
    "\n",
    "        img_id = int(d[\"image_id\"])\n",
    "        cat_id = int(d[\"category_id\"])\n",
    "\n",
    "        x, y, w, h = d[\"bbox\"]\n",
    "        x1, y1, x2, y2 = x, y, x + w, y + h\n",
    "\n",
    "        per_image.setdefault(img_id, []).append((cat_id, score, x1, y1, x2, y2))\n",
    "\n",
    "    pred_dict = {}\n",
    "    for img_id, fname in id_to_fname.items():\n",
    "        preds = sorted(per_image.get(img_id, []), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        tokens = []\n",
    "        for cat, sc, x1, y1, x2, y2 in preds:\n",
    "            tokens.extend([\n",
    "                str(cat),\n",
    "                f\"{sc:.6f}\",\n",
    "                f\"{x1:.1f}\",\n",
    "                f\"{y1:.1f}\",\n",
    "                f\"{x2:.1f}\",\n",
    "                f\"{y2:.1f}\",\n",
    "            ])\n",
    "\n",
    "        pred_dict[fname] = \" \".join(tokens)\n",
    "\n",
    "    return pred_dict\n",
    "\n",
    "\n",
    "def save_submission_with_sample(\n",
    "    pred_dict: Dict[str, str],\n",
    "    sample_csv_path: Path,\n",
    "    out_csv_path: Path\n",
    ") -> None:\n",
    "\n",
    "    sample = pd.read_csv(sample_csv_path)\n",
    "\n",
    "    if \"image_id\" not in sample.columns or \"PredictionString\" not in sample.columns:\n",
    "        raise ValueError(f\"샘플 컬럼이 예상과 다름: {list(sample.columns)}\")\n",
    "\n",
    "    sample[\"PredictionString\"] = sample[\"image_id\"].map(lambda x: pred_dict.get(x, \"\"))\n",
    "\n",
    "    out_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sample.to_csv(out_csv_path, index=False)\n",
    "\n",
    "    print(\"Saved submission:\", out_csv_path)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2) 사전 체크\n",
    "# -----------------------\n",
    "\n",
    "assert TEST_JSON_FULL.exists(), f\"test.json 없음: {TEST_JSON_FULL}\"\n",
    "assert SAMPLE_SUB_DIR.exists(), f\"sample_submission 폴더 없음: {SAMPLE_SUB_DIR}\"\n",
    "assert EXP_WORK_DIR.exists(), f\"실험 폴더 없음: {EXP_WORK_DIR}\"\n",
    "\n",
    "sample_csv = pick_sample_csv(SAMPLE_SUB_DIR)\n",
    "print(\"Using sample csv:\", sample_csv)\n",
    "\n",
    "ckpt = find_checkpoint(EXP_WORK_DIR)\n",
    "if ckpt is None:\n",
    "    raise FileNotFoundError(f\"checkpoint 없음: {EXP_WORK_DIR}\")\n",
    "\n",
    "print(\"checkpoint:\", ckpt)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 3) base cfg 지정\n",
    "#    학습 로그에서 선택된 cfg와 동일하게 맞추는 것이 가장 안정적\n",
    "# -----------------------\n",
    "\n",
    "base_cfg_path = MMD_ROOT / \"configs/rtmdet/rtmdet_l_8xb32-300e_coco.py\"\n",
    "assert base_cfg_path.exists(), f\"base cfg 없음: {base_cfg_path}\"\n",
    "print(\"Using base cfg:\", base_cfg_path)\n",
    "\n",
    "register_all_modules(init_default_scope=True)\n",
    "\n",
    "test_cfg = Config.fromfile(str(base_cfg_path))\n",
    "test_cfg.default_scope = \"mmdet\"\n",
    "\n",
    "# data_root\n",
    "test_cfg.data_root = str(FULL_DATA_ROOT)\n",
    "\n",
    "# test_dataloader 구성\n",
    "if \"test_dataloader\" not in test_cfg:\n",
    "    test_cfg.test_dataloader = test_cfg.val_dataloader\n",
    "\n",
    "loader = test_cfg.test_dataloader\n",
    "ds_cfg = loader[\"dataset\"] if \"dataset\" in loader else loader\n",
    "\n",
    "ds_cfg.metainfo = dict(classes=CLASSES)\n",
    "ds_cfg.data_root = str(FULL_DATA_ROOT)\n",
    "ds_cfg.ann_file = str(TEST_JSON_FULL)\n",
    "ds_cfg.data_prefix = dict(img=\"\")\n",
    "\n",
    "# pipeline 스케일 고정\n",
    "if hasattr(ds_cfg, \"pipeline\"):\n",
    "    set_img_scale(ds_cfg.pipeline, IMAGE_SCALE)\n",
    "\n",
    "# 클래스 수 고정\n",
    "set_num_classes(test_cfg.model, len(CLASSES))\n",
    "\n",
    "# 배치/워커\n",
    "test_cfg.test_dataloader.batch_size = 1\n",
    "test_cfg.test_dataloader.num_workers = 2\n",
    "\n",
    "# evaluator: COCO bbox json만 저장\n",
    "out_prefix = EXP_WORK_DIR / f\"{EXP_NAME}_test\"\n",
    "test_cfg.test_evaluator = dict(\n",
    "    type=\"CocoMetric\",\n",
    "    ann_file=str(TEST_JSON_FULL),\n",
    "    metric=\"bbox\",\n",
    "    format_only=True,\n",
    "    outfile_prefix=str(out_prefix),\n",
    ")\n",
    "\n",
    "# checkpoint 로드\n",
    "test_cfg.load_from = str(ckpt)\n",
    "\n",
    "# 학습 관련 설정 제거\n",
    "test_cfg.train_dataloader = None\n",
    "test_cfg.train_cfg = None\n",
    "test_cfg.optim_wrapper = None\n",
    "if hasattr(test_cfg, \"param_scheduler\"):\n",
    "    test_cfg.param_scheduler = None\n",
    "if hasattr(test_cfg, \"val_dataloader\"):\n",
    "    test_cfg.val_dataloader = None\n",
    "if hasattr(test_cfg, \"val_cfg\"):\n",
    "    test_cfg.val_cfg = None\n",
    "if hasattr(test_cfg, \"val_evaluator\"):\n",
    "    test_cfg.val_evaluator = None\n",
    "\n",
    "# work_dir 고정\n",
    "test_cfg.work_dir = str(EXP_WORK_DIR)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 4) Runner test 실행\n",
    "# -----------------------\n",
    "\n",
    "runner = Runner.from_cfg(test_cfg)\n",
    "runner.test()\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 5) bbox json -> submission\n",
    "# -----------------------\n",
    "\n",
    "bbox_json = EXP_WORK_DIR / f\"{EXP_NAME}_test.bbox.json\"\n",
    "if not bbox_json.exists():\n",
    "    cand = sorted(EXP_WORK_DIR.glob(\"*_test.bbox.json\"))\n",
    "    if cand:\n",
    "        bbox_json = cand[-1]\n",
    "\n",
    "print(\"bbox json:\", bbox_json)\n",
    "if not bbox_json.exists():\n",
    "    raise FileNotFoundError(\"bbox json 생성 실패\")\n",
    "\n",
    "pred_dict = coco_bbox_json_to_prediction_dict(\n",
    "    bbox_json=bbox_json,\n",
    "    test_json=TEST_JSON_FULL,\n",
    "    score_thr=0.05\n",
    ")\n",
    "\n",
    "out_csv = EXP_WORK_DIR / f\"{EXP_NAME}_submission_full.csv\"\n",
    "save_submission_with_sample(pred_dict, sample_csv, out_csv)\n",
    "\n",
    "print(\"단일 모델 전체 테스트 추론 완료\")\n",
    "print(\"제출 파일:\", out_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
