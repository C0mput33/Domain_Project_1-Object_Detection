{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb510bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "준비 완료\n",
      "EXP_NAME: sparse_rcnn_r50_1024_stage_aug14\n",
      "IMAGE_SIZE: (1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 이 셀은 노트북에서 가장 먼저 실행하는 공통 준비 셀입니다.\n",
    "# 경로, 클래스, 시드, 기본 상수를 한 곳에서 관리하기 위해 분리했습니다.\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1) 데이터 루트 경로를 설정합니다.\n",
    "#    AI Stages 환경에서 사용자가 쓰던 경로 패턴을 그대로 맞췄습니다.\n",
    "FULL_DATA_ROOT = Path(\"/data/ephemeral/home/model/dataset\")\n",
    "\n",
    "# 2) 원본 train.json 경로를 지정합니다.\n",
    "#    train/val split을 새로 만들기 위해 필요합니다.\n",
    "TRAIN_JSON = FULL_DATA_ROOT / \"train.json\"\n",
    "\n",
    "# 3) test.json 경로를 지정합니다.\n",
    "#    추론 시 샘플 제출 파일을 만들 때 필요합니다.\n",
    "TEST_JSON = FULL_DATA_ROOT / \"test.json\"\n",
    "\n",
    "# 4) sample_submission 폴더 경로를 지정합니다.\n",
    "SAMPLE_SUB_DIR = Path(\"/data/ephemeral/home/model/sample_submission\")\n",
    "\n",
    "# 5) 실험 결과가 저장될 work_dirs 루트를 지정합니다.\n",
    "WORK_DIR_ROOT = Path(\"/data/ephemeral/home/model/work_dirs_single\")\n",
    "\n",
    "# 6) 이번 실험의 모델 이름(폴더명)입니다.\n",
    "#    학습/추론 셀에서 반드시 동일하게 사용해야 체크포인트를 찾습니다.\n",
    "EXP_NAME = \"sparse_rcnn_r50_1024_stage_aug14\"\n",
    "\n",
    "# 7) 입력 이미지 크기를 통일해서 실험 변수를 줄입니다.\n",
    "#    사용자의 기존 1024 전략을 유지합니다.\n",
    "IMAGE_SIZE = (1024, 1024)\n",
    "\n",
    "# 8) 클래스 정의를 대회 포맷에 맞춰 고정합니다.\n",
    "CLASSES = (\n",
    "    \"General trash\",\n",
    "    \"Paper\",\n",
    "    \"Paper pack\",\n",
    "    \"Metal\",\n",
    "    \"Glass\",\n",
    "    \"Plastic\",\n",
    "    \"Styrofoam\",\n",
    "    \"Plastic bag\",\n",
    "    \"Battery\",\n",
    "    \"Clothing\",\n",
    ")\n",
    "\n",
    "# 9) 재현성을 위해 시드를 고정합니다.\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    # 파이썬 기본 랜덤 시드 고정\n",
    "    random.seed(seed)\n",
    "    # 넘파이 랜덤 시드 고정\n",
    "    np.random.seed(seed)\n",
    "    # 해시 기반 연산 시드 고정\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "# 10) 경로 존재 여부를 사전에 확인해 불필요한 런타임 오류를 줄입니다.\n",
    "assert TRAIN_JSON.exists(), f\"train.json 없음: {TRAIN_JSON}\"\n",
    "assert TEST_JSON.exists(), f\"test.json 없음: {TEST_JSON}\"\n",
    "assert SAMPLE_SUB_DIR.exists(), f\"sample_submission 폴더 없음: {SAMPLE_SUB_DIR}\"\n",
    "\n",
    "print(\"준비 완료\")\n",
    "print(\"EXP_NAME:\", EXP_NAME)\n",
    "print(\"IMAGE_SIZE:\", IMAGE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78270783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split: /data/ephemeral/home/model/dataset/splits_single/train_split_88.json\n",
      "val split  : /data/ephemeral/home/model/dataset/splits_single/val_split_12.json\n",
      "train images: 4297 val images: 586\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 이 셀은 train.json을 읽어서 원하는 비율로 train/val split 파일을 생성합니다.\n",
    "# 사용자가 원한 0.88/0.12를 기본값으로 두되,\n",
    "# split_ratio만 바꾸면 다른 비율도 바로 실험할 수 있게 했습니다.\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "\n",
    "# 1) split 결과 저장 폴더를 지정합니다.\n",
    "SPLIT_DIR = FULL_DATA_ROOT / \"splits_single\"\n",
    "SPLIT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2) 기본 비율을 설정합니다.\n",
    "#    튜닝 안정성과 학습 데이터 확장을 동시에 고려해 0.88을 기본으로 둡니다.\n",
    "split_ratio = 0.88  # 필요하면 0.85, 0.9 등으로 변경\n",
    "\n",
    "train_out = SPLIT_DIR / f\"train_split_{int(split_ratio*100)}.json\"\n",
    "val_out   = SPLIT_DIR / f\"val_split_{int((1-split_ratio)*100)}.json\"\n",
    "\n",
    "# 3) 원본 COCO 형식 train.json을 로드합니다.\n",
    "with open(TRAIN_JSON, \"r\") as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "# 4) 이미지 단위로 split 해야 annotation과 매칭이 유지됩니다.\n",
    "images = coco[\"images\"]\n",
    "anns = coco[\"annotations\"]\n",
    "\n",
    "# 5) 이미지 id 목록을 추출합니다.\n",
    "img_ids = [img[\"id\"] for img in images]\n",
    "\n",
    "# 6) 시드 고정 상태로 셔플합니다.\n",
    "random.shuffle(img_ids)\n",
    "\n",
    "# 7) 분할 지점을 계산합니다.\n",
    "cut = int(len(img_ids) * split_ratio)\n",
    "\n",
    "train_ids = set(img_ids[:cut])\n",
    "val_ids   = set(img_ids[cut:])\n",
    "\n",
    "# 8) 이미지 리스트를 분리합니다.\n",
    "train_images = [img for img in images if img[\"id\"] in train_ids]\n",
    "val_images   = [img for img in images if img[\"id\"] in val_ids]\n",
    "\n",
    "# 9) annotation도 이미지 id 기준으로 분리합니다.\n",
    "train_anns = [a for a in anns if a[\"image_id\"] in train_ids]\n",
    "val_anns   = [a for a in anns if a[\"image_id\"] in val_ids]\n",
    "\n",
    "# 10) 카테고리/기타 메타는 그대로 유지합니다.\n",
    "base = {k: v for k, v in coco.items() if k not in [\"images\", \"annotations\"]}\n",
    "\n",
    "train_coco = dict(**base, images=train_images, annotations=train_anns)\n",
    "val_coco   = dict(**base, images=val_images, annotations=val_anns)\n",
    "\n",
    "# 11) 저장합니다.\n",
    "with open(train_out, \"w\") as f:\n",
    "    json.dump(train_coco, f)\n",
    "\n",
    "with open(val_out, \"w\") as f:\n",
    "    json.dump(val_coco, f)\n",
    "\n",
    "print(\"train split:\", train_out)\n",
    "print(\"val split  :\", val_out)\n",
    "print(\"train images:\", len(train_images), \"val images:\", len(val_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25010178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config 준비 완료\n",
      "base cfg: /data/ephemeral/home/model/baseline/mmdetection/configs/sparse_rcnn/sparse-rcnn_r50_fpn_300-proposals_crop-ms-480-800-3x_coco.py\n",
      "work_dir: /data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14\n",
      "train ann: /data/ephemeral/home/model/dataset/splits_single/train_split_88.json\n",
      "val ann  : /data/ephemeral/home/model/dataset/splits_single/val_split_12.json\n",
      "max_epochs: 14\n",
      "wandb entity/project: boostcamp8-cv-08 / kim\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 이 셀은 MMDetection의 base config를 불러와\n",
    "# 데이터셋 경로, 클래스 수, 학습 epoch,\n",
    "# 그리고 사용자가 정리한 증강 철학을 반영한 3-스테이지 파이프라인을 적용합니다.\n",
    "# 마지막으로 W&B 팀 엔티티/프로젝트 설정까지 구성합니다.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "from mmdet.utils import register_all_modules\n",
    "\n",
    "# 1) MMDetection 루트를 지정합니다.\n",
    "MMD_ROOT = Path(\"/data/ephemeral/home/model/baseline/mmdetection\")\n",
    "\n",
    "# 2) Sparse R-CNN 기본 config를 선택합니다.\n",
    "#    사진 목록에 없던 새로운 단일 모델 축을 만들기 위한 선택입니다.\n",
    "base_cfg_rel = \"configs/sparse_rcnn/sparse-rcnn_r50_fpn_300-proposals_crop-ms-480-800-3x_coco.py\"\n",
    "base_cfg_path = MMD_ROOT / base_cfg_rel\n",
    "\n",
    "assert base_cfg_path.exists(), f\"base cfg 없음: {base_cfg_path}\"\n",
    "\n",
    "# 3) split 파일 경로를 위 셀에서 만든 이름 규칙과 맞춥니다.\n",
    "SPLIT_DIR = FULL_DATA_ROOT / \"splits_single\"\n",
    "split_ratio = 0.88  # 셀 1과 동일하게 맞춰야 합니다.\n",
    "\n",
    "TRAIN_SPLIT = SPLIT_DIR / f\"train_split_{int(split_ratio*100)}.json\"\n",
    "VAL_SPLIT   = SPLIT_DIR / f\"val_split_{int((1-split_ratio)*100)}.json\"\n",
    "\n",
    "assert TRAIN_SPLIT.exists(), f\"train split 없음: {TRAIN_SPLIT}\"\n",
    "assert VAL_SPLIT.exists(), f\"val split 없음: {VAL_SPLIT}\"\n",
    "\n",
    "# 4) 모델/데이터 모듈을 등록합니다.\n",
    "register_all_modules(init_default_scope=True)\n",
    "\n",
    "# 5) base config를 로드합니다.\n",
    "cfg = Config.fromfile(str(base_cfg_path))\n",
    "cfg.default_scope = \"mmdet\"\n",
    "\n",
    "# 6) 실험 work_dir을 고정합니다.\n",
    "#    체크포인트/로그 경로 혼선을 방지합니다.\n",
    "EXP_WORK_DIR = WORK_DIR_ROOT / EXP_NAME\n",
    "cfg.work_dir = str(EXP_WORK_DIR)\n",
    "\n",
    "# 7) 데이터 루트를 대회 데이터 경로로 교체합니다.\n",
    "cfg.data_root = str(FULL_DATA_ROOT)\n",
    "\n",
    "# 8) train/val dataloader의 dataset 설정을 가져와 수정합니다.\n",
    "#    MMDet 버전에 따라 dict 구조가 조금 다르므로 안전하게 접근합니다.\n",
    "train_loader = cfg.train_dataloader\n",
    "val_loader = cfg.val_dataloader\n",
    "\n",
    "train_ds = train_loader.get(\"dataset\", train_loader)\n",
    "val_ds = val_loader.get(\"dataset\", val_loader)\n",
    "\n",
    "# 9) 클래스 메타 정보를 강제 설정합니다.\n",
    "train_ds.metainfo = dict(classes=CLASSES)\n",
    "val_ds.metainfo = dict(classes=CLASSES)\n",
    "\n",
    "# 10) annotation 파일 경로를 split json으로 교체합니다.\n",
    "train_ds.ann_file = str(TRAIN_SPLIT)\n",
    "val_ds.ann_file   = str(VAL_SPLIT)\n",
    "\n",
    "# 11) 이미지 경로 prefix를 맞춥니다.\n",
    "#     대회 데이터 구조에 따라 img=\"\"가 안전합니다.\n",
    "train_ds.data_prefix = dict(img=\"\")\n",
    "val_ds.data_prefix   = dict(img=\"\")\n",
    "\n",
    "# 12) 사용자 전략을 반영한 3-스테이지 파이프라인을 정의합니다.\n",
    "#     Cascade/RCNN 계열에 맞는 mild~medium 증강 기조를 유지합니다.\n",
    "train_pipeline_stage1 = [\n",
    "    dict(type=\"LoadImageFromFile\"),\n",
    "    dict(type=\"LoadAnnotations\", with_bbox=True),\n",
    "\n",
    "    # 기본 flip\n",
    "    dict(type=\"RandomFlip\", prob=0.5),\n",
    "\n",
    "    # small object 개선을 위한 보수적 MinIoU Random Crop\n",
    "    dict(\n",
    "        type=\"MinIoURandomCrop\",\n",
    "        min_ious=[0.4, 0.5, 0.6],\n",
    "        min_crop_size=0.6,\n",
    "    ),\n",
    "\n",
    "    # 멀티스케일 리사이즈 (과도한 변형 방지 위해 스케일을 3개로 제한)\n",
    "    dict(\n",
    "        type=\"RandomChoiceResize\",\n",
    "        scales=[(800, 800), (896, 896), (1024, 1024)],\n",
    "        keep_ratio=True,\n",
    "    ),\n",
    "\n",
    "    # 색/밝기 기반의 안전한 photometric 증강\n",
    "    dict(\n",
    "        type=\"PhotoMetricDistortion\",\n",
    "        brightness_delta=32,\n",
    "        contrast_range=(0.5, 1.5),\n",
    "        saturation_range=(0.5, 1.5),\n",
    "        hue_delta=18\n",
    "    ),\n",
    "\n",
    "    # CutOut은 초반에만 사용 (과하면 localization 손상 가능)\n",
    "    dict(\n",
    "        type=\"CutOut\",\n",
    "        n_holes=5,\n",
    "        cutout_shape=[(32, 32), (48, 48), (64, 64)]\n",
    "    ),\n",
    "\n",
    "    dict(type=\"PackDetInputs\"),\n",
    "]\n",
    "\n",
    "train_pipeline_stage2 = [\n",
    "    dict(type=\"LoadImageFromFile\"),\n",
    "    dict(type=\"LoadAnnotations\", with_bbox=True),\n",
    "\n",
    "    dict(type=\"RandomFlip\", prob=0.5),\n",
    "\n",
    "    dict(\n",
    "        type=\"MinIoURandomCrop\",\n",
    "        min_ious=[0.4, 0.5, 0.6],\n",
    "        min_crop_size=0.6,\n",
    "    ),\n",
    "\n",
    "    dict(\n",
    "        type=\"RandomChoiceResize\",\n",
    "        scales=[(800, 800), (896, 896), (1024, 1024)],\n",
    "        keep_ratio=True,\n",
    "    ),\n",
    "\n",
    "    dict(\n",
    "        type=\"PhotoMetricDistortion\",\n",
    "        brightness_delta=32,\n",
    "        contrast_range=(0.5, 1.5),\n",
    "        saturation_range=(0.5, 1.5),\n",
    "        hue_delta=18\n",
    "    ),\n",
    "\n",
    "    # Stage 2에서는 CutOut을 제거해 박스 품질 저하를 줄입니다.\n",
    "    dict(type=\"PackDetInputs\"),\n",
    "]\n",
    "\n",
    "train_pipeline_stage3 = [\n",
    "    dict(type=\"LoadImageFromFile\"),\n",
    "    dict(type=\"LoadAnnotations\", with_bbox=True),\n",
    "\n",
    "    # 후반에는 inference와 가까운 분포로 수렴시키기 위해 단순화합니다.\n",
    "    dict(type=\"RandomFlip\", prob=0.5),\n",
    "\n",
    "    # 최종 크기 고정\n",
    "    dict(type=\"Resize\", scale=IMAGE_SIZE, keep_ratio=True),\n",
    "\n",
    "    # 색 증강도 약하게 유지하거나 필요 시 제거 가능\n",
    "    dict(\n",
    "        type=\"PhotoMetricDistortion\",\n",
    "        brightness_delta=16,\n",
    "        contrast_range=(0.8, 1.2),\n",
    "        saturation_range=(0.8, 1.2),\n",
    "        hue_delta=10\n",
    "    ),\n",
    "\n",
    "    dict(type=\"PackDetInputs\"),\n",
    "]\n",
    "\n",
    "# 13) 실제 train dataset pipeline을 Stage 1로 초기 설정합니다.\n",
    "train_ds.pipeline = train_pipeline_stage1\n",
    "\n",
    "# 14) val pipeline은 안정적인 고정 리사이즈로 통일합니다.\n",
    "val_ds.pipeline = [\n",
    "    dict(type=\"LoadImageFromFile\"),\n",
    "    dict(type=\"Resize\", scale=IMAGE_SIZE, keep_ratio=True),\n",
    "    dict(type=\"PackDetInputs\"),\n",
    "]\n",
    "\n",
    "# 15) 모델의 num_classes를 데이터셋 클래스 수에 맞춥니다.\n",
    "#     config 내부를 재귀적으로 탐색해 num_classes 키를 찾아 수정합니다.\n",
    "def set_num_classes(node, num_classes: int):\n",
    "    if isinstance(node, dict):\n",
    "        if \"num_classes\" in node:\n",
    "            node[\"num_classes\"] = num_classes\n",
    "        for v in node.values():\n",
    "            set_num_classes(v, num_classes)\n",
    "    elif isinstance(node, list):\n",
    "        for v in node:\n",
    "            set_num_classes(v, num_classes)\n",
    "\n",
    "set_num_classes(cfg.model, len(CLASSES))\n",
    "\n",
    "# 16) epoch 수를 14로 설정합니다.\n",
    "#     base config가 3x 스케줄일 수 있으므로\n",
    "#     max_epochs를 직접 덮어써서 실험 목적에 맞춥니다.\n",
    "cfg.train_cfg.max_epochs = 14\n",
    "\n",
    "# 17) batch size는 GPU 상황에 맞게 조정 가능합니다.\n",
    "#     여기서는 안전한 값으로 예시만 둡니다.\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "cfg.val_dataloader.batch_size = 2\n",
    "\n",
    "# 18) 파이프라인 스테이지를 epoch 비율에 따라 바꾸는 Hook을 정의합니다.\n",
    "from mmengine.hooks import Hook\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from mmengine.hooks import Hook\n",
    "from mmengine.registry import HOOKS\n",
    "\n",
    "# 같은 이름으로 여러 번 등록될 때 충돌/캐시 문제가 생길 수 있어\n",
    "# 클래스 이름을 V2로 바꿔 새 엔트리로 등록합니다.\n",
    "\n",
    "@HOOKS.register_module()\n",
    "class PipelineSwitchHookV2(Hook):\n",
    "    # stage1_end, stage2_end를 명시적으로 받되\n",
    "    # 혹시 모를 추가 인자 유입까지 안전하게 처리하기 위해 **kwargs도 받습니다.\n",
    "    def __init__(self, stage1_end=0.4, stage2_end=0.75, **kwargs):\n",
    "        self.stage1_end = stage1_end\n",
    "        self.stage2_end = stage2_end\n",
    "\n",
    "    def before_train_epoch(self, runner):\n",
    "        # 현재 epoch\n",
    "        epoch = runner.epoch\n",
    "        # 전체 학습 epoch\n",
    "        max_epochs = runner.max_epochs\n",
    "        # 진행 비율\n",
    "        ratio = (epoch + 1) / max_epochs\n",
    "\n",
    "        # 실제 Dataset 객체 접근\n",
    "        ds = runner.train_dataloader.dataset\n",
    "\n",
    "        # 1단계: 강/중 증강\n",
    "        if ratio <= self.stage1_end:\n",
    "            ds.pipeline = train_pipeline_stage1\n",
    "            runner.logger.info(\n",
    "                f\"[PipelineSwitch] Stage1 pipeline 적용 (epoch={epoch+1}/{max_epochs})\"\n",
    "            )\n",
    "\n",
    "        # 2단계: 중간 강도\n",
    "        elif ratio <= self.stage2_end:\n",
    "            ds.pipeline = train_pipeline_stage2\n",
    "            runner.logger.info(\n",
    "                f\"[PipelineSwitch] Stage2 pipeline 적용 (epoch={epoch+1}/{max_epochs})\"\n",
    "            )\n",
    "\n",
    "        # 3단계: 약한 증강(추론 분포 근접)\n",
    "        else:\n",
    "            ds.pipeline = train_pipeline_stage3\n",
    "            runner.logger.info(\n",
    "                f\"[PipelineSwitch] Stage3 pipeline 적용 (epoch={epoch+1}/{max_epochs})\"\n",
    "            )\n",
    "\n",
    "\n",
    "# 기존에 cfg.custom_hooks.append(dict(type=PipelineSwitchHook)) 를 썼다면 삭제/교체\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 기존에 PipelineSwitchHook을 넣은 줄이 있으면 제거하고 아래만 남깁니다.\n",
    "\n",
    "cfg.custom_hooks = cfg.get(\"custom_hooks\", [])\n",
    "\n",
    "cfg.custom_hooks.append(\n",
    "    dict(\n",
    "        type=\"PipelineSwitchHookV2\",  # 새 이름으로 지정\n",
    "        stage1_end=0.4,\n",
    "        stage2_end=0.75\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# 20) W&B 설정\n",
    "#     핵심은 entity를 '조직'이 아니라 '팀'으로 지정하는 것입니다.\n",
    "ENTITY = \"boostcamp8-cv-08\"\n",
    "PROJECT = \"kim\"\n",
    "\n",
    "cfg.visualizer = dict(\n",
    "    type=\"DetLocalVisualizer\",\n",
    "    vis_backends=[\n",
    "        dict(type=\"LocalVisBackend\"),\n",
    "        dict(\n",
    "            type=\"WandbVisBackend\",\n",
    "            init_kwargs=dict(\n",
    "                entity=ENTITY,\n",
    "                project=PROJECT,\n",
    "                name=EXP_NAME,\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 22) 로그 주기를 적당히 조절합니다.\n",
    "cfg.default_hooks = cfg.get(\"default_hooks\", {})\n",
    "cfg.default_hooks[\"logger\"] = dict(type=\"LoggerHook\", interval=50)\n",
    "\n",
    "print(\"Config 준비 완료\")\n",
    "print(\"base cfg:\", base_cfg_path)\n",
    "print(\"work_dir:\", cfg.work_dir)\n",
    "print(\"train ann:\", train_ds.ann_file)\n",
    "print(\"val ann  :\", val_ds.ann_file)\n",
    "print(\"max_epochs:\", cfg.train_cfg.max_epochs)\n",
    "print(\"wandb entity/project:\", ENTITY, \"/\", PROJECT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd90f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/08 08:18:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1608637542\n",
      "    GPU 0: Tesla V100-SXM2-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu121\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1608637542\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: gcc: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/08 08:18:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "custom_hooks = [\n",
      "    dict(stage1_end=0.4, stage2_end=0.75, type='PipelineSwitchHook'),\n",
      "]\n",
      "data_root = '/data/ephemeral/home/model/dataset'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 36\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        frozen_stages=1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        add_extra_convs='on_input',\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=4,\n",
      "        out_channels=256,\n",
      "        start_level=0,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    clip_border=False,\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.5,\n",
      "                        0.5,\n",
      "                        1.0,\n",
      "                        1.0,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                dropout=0.0,\n",
      "                dynamic_conv_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    feat_channels=64,\n",
      "                    in_channels=256,\n",
      "                    input_feat_shape=7,\n",
      "                    norm_cfg=dict(type='LN'),\n",
      "                    out_channels=256,\n",
      "                    type='DynamicConv'),\n",
      "                feedforward_channels=2048,\n",
      "                ffn_act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=2.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "                num_classes=10,\n",
      "                num_cls_fcs=1,\n",
      "                num_ffn_fcs=2,\n",
      "                num_heads=8,\n",
      "                num_reg_fcs=3,\n",
      "                type='DIIHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=2, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=6,\n",
      "        proposal_feature_channel=256,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "        ],\n",
      "        type='SparseRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        num_proposals=300,\n",
      "        proposal_feature_channel=256,\n",
      "        type='EmbeddingRPNHead'),\n",
      "    test_cfg=dict(rcnn=dict(max_per_img=300), rpn=None),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    match_costs=[\n",
      "                        dict(type='FocalLossCost', weight=2.0),\n",
      "                        dict(box_format='xyxy', type='BBoxL1Cost', weight=5.0),\n",
      "                        dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                    ],\n",
      "                    type='HungarianAssigner'),\n",
      "                pos_weight=1,\n",
      "                sampler=dict(type='PseudoSampler')),\n",
      "        ],\n",
      "        rpn=None),\n",
      "    type='SparseRCNN')\n",
      "num_proposals = 300\n",
      "num_stages = 6\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=1, norm_type=2),\n",
      "    optimizer=dict(lr=2.5e-05, type='AdamW', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=36,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            27,\n",
      "            33,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2017.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2017/'),\n",
      "        data_root='data/coco/',\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=14, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/data/ephemeral/home/model/dataset/splits_single/train_split_88.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='data/coco/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                min_crop_size=0.6,\n",
      "                min_ious=[\n",
      "                    0.4,\n",
      "                    0.5,\n",
      "                    0.6,\n",
      "                ],\n",
      "                type='MinIoURandomCrop'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                scales=[\n",
      "                    (\n",
      "                        800,\n",
      "                        800,\n",
      "                    ),\n",
      "                    (\n",
      "                        896,\n",
      "                        896,\n",
      "                    ),\n",
      "                    (\n",
      "                        1024,\n",
      "                        1024,\n",
      "                    ),\n",
      "                ],\n",
      "                type='RandomChoiceResize'),\n",
      "            dict(\n",
      "                brightness_delta=32,\n",
      "                contrast_range=(\n",
      "                    0.5,\n",
      "                    1.5,\n",
      "                ),\n",
      "                hue_delta=18,\n",
      "                saturation_range=(\n",
      "                    0.5,\n",
      "                    1.5,\n",
      "                ),\n",
      "                type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                cutout_shape=[\n",
      "                    (\n",
      "                        32,\n",
      "                        32,\n",
      "                    ),\n",
      "                    (\n",
      "                        48,\n",
      "                        48,\n",
      "                    ),\n",
      "                    (\n",
      "                        64,\n",
      "                        64,\n",
      "                    ),\n",
      "                ],\n",
      "                n_holes=5,\n",
      "                type='CutOut'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            480,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            512,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            544,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            576,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            608,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            640,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            672,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            704,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            736,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            768,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            800,\n",
      "                            1333,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            400,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            500,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            600,\n",
      "                            1333,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "                dict(\n",
      "                    allow_negative_crop=True,\n",
      "                    crop_size=(\n",
      "                        384,\n",
      "                        600,\n",
      "                    ),\n",
      "                    crop_type='absolute_range',\n",
      "                    type='RandomCrop'),\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scales=[\n",
      "                        (\n",
      "                            480,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            512,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            544,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            576,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            608,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            640,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            672,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            704,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            736,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            768,\n",
      "                            1333,\n",
      "                        ),\n",
      "                        (\n",
      "                            800,\n",
      "                            1333,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomChoiceResize'),\n",
      "            ],\n",
      "        ],\n",
      "        type='RandomChoice'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/data/ephemeral/home/model/dataset/splits_single/val_split_12.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='data/coco/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(\n",
      "            init_kwargs=dict(\n",
      "                entity='boostcamp8-cv-08',\n",
      "                name='sparse_rcnn_r50_1024_stage_aug14',\n",
      "                project='kim'),\n",
      "            type='WandbVisBackend'),\n",
      "    ])\n",
      "work_dir = '/data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhae24923\u001b[0m (\u001b[33mboostcamp8-cv-08\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/model/work_dirs_single/sparse_rcnn_r50_1024_stage_aug14/20251208_081845/vis_data/wandb/run-20251208_081850-f5bcatyx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp8-cv-08/kim/runs/f5bcatyx' target=\"_blank\">sparse_rcnn_r50_1024_stage_aug14</a></strong> to <a href='https://wandb.ai/boostcamp8-cv-08/kim' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp8-cv-08/kim' target=\"_blank\">https://wandb.ai/boostcamp8-cv-08/kim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp8-cv-08/kim/runs/f5bcatyx' target=\"_blank\">https://wandb.ai/boostcamp8-cv-08/kim/runs/f5bcatyx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m No relevant files were detected in the specified directory. No code will be logged to your run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/08 08:18:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PipelineSwitchHook.__init__() got an unexpected keyword argument 'stage1_end'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmmengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Runner\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 1) Runner를 config로 생성합니다.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[43mRunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 2) 학습을 시작합니다.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m runner\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/mmengine/runner/runner.py:462\u001b[0m, in \u001b[0;36mRunner.from_cfg\u001b[0;34m(cls, cfg)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a runner from config.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m    Runner: A runner build from ``cfg``.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    461\u001b[0m cfg \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(cfg)\n\u001b[0;32m--> 462\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwork_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_dataloader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_dataloader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_dataloader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_cfg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_cfg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_cfg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_scale_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto_scale_lr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptim_wrapper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparam_scheduler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_evaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_evaluator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_evaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_evaluator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault_hooks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustom_hooks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_preprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_preprocessor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload_from\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlauncher\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menv_cfg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdist_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnccl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_processor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_level\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mINFO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisualizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisualizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault_scope\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmmengine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandomness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexperiment_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m runner\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/mmengine/runner/runner.py:442\u001b[0m, in \u001b[0;36mRunner.__init__\u001b[0;34m(self, model, work_dir, train_dataloader, val_dataloader, test_dataloader, train_cfg, val_cfg, test_cfg, auto_scale_lr, optim_wrapper, param_scheduler, val_evaluator, test_evaluator, default_hooks, custom_hooks, data_preprocessor, load_from, resume, launcher, env_cfg, log_processor, log_level, visualizer, default_scope, randomness, experiment_name, cfg)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks: List[Hook] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# register hooks to `self._hooks`\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_hooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_hooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# log hooks information\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHooks will be executed in the following \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    445\u001b[0m                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_hooks_info()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/mmengine/runner/runner.py:1995\u001b[0m, in \u001b[0;36mRunner.register_hooks\u001b[0;34m(self, default_hooks, custom_hooks)\u001b[0m\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_default_hooks(default_hooks)\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m custom_hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1995\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_custom_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_hooks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/mmengine/runner/runner.py:1976\u001b[0m, in \u001b[0;36mRunner.register_custom_hooks\u001b[0;34m(self, hooks)\u001b[0m\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Register custom hooks into hook list.\u001b[39;00m\n\u001b[1;32m   1970\u001b[0m \n\u001b[1;32m   1971\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;124;03m    hooks (list[Hook | dict]): List of hooks or configs to be\u001b[39;00m\n\u001b[1;32m   1973\u001b[0m \u001b[38;5;124;03m        registered.\u001b[39;00m\n\u001b[1;32m   1974\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m hooks:\n\u001b[0;32m-> 1976\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/mmengine/runner/runner.py:1877\u001b[0m, in \u001b[0;36mRunner.register_hook\u001b[0;34m(self, hook, priority)\u001b[0m\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m hook:\n\u001b[1;32m   1875\u001b[0m         _priority \u001b[38;5;241m=\u001b[39m hook\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1877\u001b[0m     hook_obj \u001b[38;5;241m=\u001b[39m \u001b[43mHOOKS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1878\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1879\u001b[0m     hook_obj \u001b[38;5;241m=\u001b[39m hook\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/mmengine/registry/registry.py:570\u001b[0m, in \u001b[0;36mRegistry.build\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build an instance.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    Build an instance by calling :attr:`build_func`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m        >>> model = MODELS.build(cfg)\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/mmengine/registry/build_functions.py:121\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    119\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj_cls\u001b[38;5;241m.\u001b[39mget_instance(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (inspect\u001b[38;5;241m.\u001b[39misclass(obj_cls) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj_cls)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj_cls)):\n\u001b[1;32m    125\u001b[0m     print_log(\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instance is built from \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistry, and its implementation can be found in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    130\u001b[0m         level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mDEBUG)\n",
      "\u001b[0;31mTypeError\u001b[0m: PipelineSwitchHook.__init__() got an unexpected keyword argument 'stage1_end'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 이 셀은 위에서 구성한 cfg로 학습을 시작합니다.\n",
    "# W&B 로그인은 터미널에서 이미 해두었다고 가정합니다.\n",
    "\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "# 1) Runner를 config로 생성합니다.\n",
    "runner = Runner.from_cfg(cfg)\n",
    "\n",
    "# 2) 학습을 시작합니다.\n",
    "runner.train()\n",
    "\n",
    "print(\"학습 완료\")\n",
    "print(\"체크포인트 폴더:\", cfg.work_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d72f574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/model/baseline/Sparse R-CNN/wandb/run-20251208_080922-mpaq5vaz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp8-cv-08/kim/runs/mpaq5vaz' target=\"_blank\">smoke-test</a></strong> to <a href='https://wandb.ai/boostcamp8-cv-08/kim' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp8-cv-08/kim' target=\"_blank\">https://wandb.ai/boostcamp8-cv-08/kim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp8-cv-08/kim/runs/mpaq5vaz' target=\"_blank\">https://wandb.ai/boostcamp8-cv-08/kim/runs/mpaq5vaz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ping</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ping</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smoke-test</strong> at: <a href='https://wandb.ai/boostcamp8-cv-08/kim/runs/mpaq5vaz' target=\"_blank\">https://wandb.ai/boostcamp8-cv-08/kim/runs/mpaq5vaz</a><br> View project at: <a href='https://wandb.ai/boostcamp8-cv-08/kim' target=\"_blank\">https://wandb.ai/boostcamp8-cv-08/kim</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251208_080922-mpaq5vaz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B smoke test done\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# 팀 엔티티를 반드시 지정합니다.\n",
    "run = wandb.init(\n",
    "    entity=\"boostcamp8-cv-08\",\n",
    "    project=\"kim\",\n",
    "    name=\"smoke-test\",\n",
    ")\n",
    "\n",
    "run.log({\"ping\": 1})\n",
    "run.finish()\n",
    "\n",
    "print(\"W&B smoke test done\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
