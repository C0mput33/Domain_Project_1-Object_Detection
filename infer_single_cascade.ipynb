{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b59af504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP_WORK_DIR: /data/ephemeral/home/model/work_dirs_single/cascade_rcnn_r50_1024_single\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmdet.utils import register_all_modules\n",
    "\n",
    "MMD_ROOT = Path(\"/data/ephemeral/home/model/baseline/mmdetection\")\n",
    "\n",
    "FULL_DATA_ROOT = Path(\"/data/ephemeral/home/model/dataset\")\n",
    "TEST_JSON_FULL = FULL_DATA_ROOT / \"test.json\"\n",
    "\n",
    "SAMPLE_SUB_DIR = Path(\"/data/ephemeral/home/model/sample_submission\")\n",
    "\n",
    "WORK_DIR = Path(\"/data/ephemeral/home/model/work_dirs_single\")\n",
    "EXP_NAME = \"cascade_rcnn_r50_1024_single\"\n",
    "EXP_WORK_DIR = WORK_DIR / EXP_NAME\n",
    "\n",
    "IMAGE_SCALE = (1024, 1024)\n",
    "\n",
    "CLASSES = (\n",
    "    \"General trash\",\n",
    "    \"Paper\",\n",
    "    \"Paper pack\",\n",
    "    \"Metal\",\n",
    "    \"Glass\",\n",
    "    \"Plastic\",\n",
    "    \"Styrofoam\",\n",
    "    \"Plastic bag\",\n",
    "    \"Battery\",\n",
    "    \"Clothing\",\n",
    ")\n",
    "\n",
    "print(\"EXP_WORK_DIR:\", EXP_WORK_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7872773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample csv: /data/ephemeral/home/model/sample_submission/faster_rcnn_mmdetection_submission.csv\n"
     ]
    }
   ],
   "source": [
    "def pick_sample_csv(sample_dir: Path) -> Path:\n",
    "    csvs = sorted(sample_dir.glob(\"*.csv\"))\n",
    "    if not csvs:\n",
    "        raise FileNotFoundError(f\"샘플 제출 csv가 없습니다: {sample_dir}\")\n",
    "\n",
    "    for c in csvs:\n",
    "        if \"mmdetection\" in c.name.lower():\n",
    "            return c\n",
    "\n",
    "    return csvs[0]\n",
    "\n",
    "sample_csv = pick_sample_csv(SAMPLE_SUB_DIR)\n",
    "print(\"Using sample csv:\", sample_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12be0190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: /data/ephemeral/home/model/work_dirs_single/cascade_rcnn_r50_1024_single/epoch_12.pth\n"
     ]
    }
   ],
   "source": [
    "def find_checkpoint(work_dir: Path) -> Optional[Path]:\n",
    "    last_txt = work_dir / \"last_checkpoint\"\n",
    "    if last_txt.exists():\n",
    "        p = last_txt.read_text().strip()\n",
    "        if p:\n",
    "            ck = Path(p)\n",
    "            if ck.exists():\n",
    "                return ck\n",
    "\n",
    "    ckpts = sorted(work_dir.glob(\"*.pth\"))\n",
    "    if ckpts:\n",
    "        return ckpts[-1]\n",
    "\n",
    "    return None\n",
    "\n",
    "ckpt = find_checkpoint(EXP_WORK_DIR)\n",
    "print(\"checkpoint:\", ckpt)\n",
    "\n",
    "if ckpt is None:\n",
    "    raise FileNotFoundError(\"checkpoint를 찾지 못했습니다. 학습 work_dir을 확인하세요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051f8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_img_scale(pipeline, scale):\n",
    "    for t in pipeline:\n",
    "        if isinstance(t, list):\n",
    "            set_img_scale(t, scale)\n",
    "            continue\n",
    "        if not isinstance(t, dict):\n",
    "            continue\n",
    "\n",
    "        if t.get(\"type\") in (\"Resize\", \"RandomResize\", \"RandomChoiceResize\"):\n",
    "            if \"scale\" in t:\n",
    "                t[\"scale\"] = scale\n",
    "            if \"img_scale\" in t:\n",
    "                t[\"img_scale\"] = scale\n",
    "            if \"scales\" in t:\n",
    "                t[\"scales\"] = [scale]\n",
    "\n",
    "        if \"transforms\" in t:\n",
    "            set_img_scale(t[\"transforms\"], scale)\n",
    "\n",
    "def set_num_classes(model_cfg, num_classes: int):\n",
    "    if isinstance(model_cfg, dict):\n",
    "        if \"num_classes\" in model_cfg:\n",
    "            model_cfg[\"num_classes\"] = num_classes\n",
    "        for v in model_cfg.values():\n",
    "            set_num_classes(v, num_classes)\n",
    "    elif isinstance(model_cfg, list):\n",
    "        for v in model_cfg:\n",
    "            set_num_classes(v, num_classes)\n",
    "\n",
    "def build_test_cfg(ckpt_path: Path) -> Config:\n",
    "    register_all_modules(init_default_scope=True)\n",
    "\n",
    "    base_cfg_rel = \"configs/cascade_rcnn/cascade-rcnn_r50_fpn_1x_coco.py\"\n",
    "    base_cfg_path = MMD_ROOT / base_cfg_rel\n",
    "    if not base_cfg_path.exists():\n",
    "        raise FileNotFoundError(f\"base config 없음: {base_cfg_path}\")\n",
    "\n",
    "    cfg = Config.fromfile(str(base_cfg_path))\n",
    "    cfg.default_scope = \"mmdet\"\n",
    "\n",
    "    # data_root\n",
    "    cfg.data_root = str(FULL_DATA_ROOT)\n",
    "\n",
    "    # test_dataloader 보정\n",
    "    if \"test_dataloader\" not in cfg:\n",
    "        cfg.test_dataloader = cfg.val_dataloader\n",
    "\n",
    "    loader = cfg.test_dataloader\n",
    "    ds_cfg = loader[\"dataset\"] if \"dataset\" in loader else loader\n",
    "\n",
    "    ds_cfg.metainfo = dict(classes=CLASSES)\n",
    "    ds_cfg.data_root = str(FULL_DATA_ROOT)\n",
    "    ds_cfg.ann_file = str(TEST_JSON_FULL)\n",
    "    ds_cfg.data_prefix = dict(img=\"\")\n",
    "\n",
    "    # pipeline 스케일 고정\n",
    "    if hasattr(ds_cfg, \"pipeline\"):\n",
    "        set_img_scale(ds_cfg.pipeline, IMAGE_SCALE)\n",
    "\n",
    "    # 클래스 수 고정\n",
    "    set_num_classes(cfg.model, len(CLASSES))\n",
    "\n",
    "    # 배치/워커\n",
    "    cfg.test_dataloader.batch_size = 1\n",
    "    cfg.test_dataloader.num_workers = 2\n",
    "\n",
    "    # COCO bbox json만 출력\n",
    "    out_prefix = EXP_WORK_DIR / f\"{EXP_NAME}_test\"\n",
    "\n",
    "    cfg.test_evaluator = dict(\n",
    "        type=\"CocoMetric\",\n",
    "        ann_file=str(TEST_JSON_FULL),\n",
    "        metric=\"bbox\",\n",
    "        format_only=True,\n",
    "        outfile_prefix=str(out_prefix),\n",
    "    )\n",
    "\n",
    "    # checkpoint 로드\n",
    "    cfg.load_from = str(ckpt_path)\n",
    "\n",
    "    # 추론 전용으로 학습 관련 제거\n",
    "    cfg.train_dataloader = None\n",
    "    cfg.train_cfg = None\n",
    "    cfg.optim_wrapper = None\n",
    "    if hasattr(cfg, \"param_scheduler\"):\n",
    "        cfg.param_scheduler = None\n",
    "    if hasattr(cfg, \"val_dataloader\"):\n",
    "        cfg.val_dataloader = None\n",
    "    if hasattr(cfg, \"val_cfg\"):\n",
    "        cfg.val_cfg = None\n",
    "    if hasattr(cfg, \"val_evaluator\"):\n",
    "        cfg.val_evaluator = None\n",
    "\n",
    "    # work_dir 고정\n",
    "    cfg.work_dir = str(EXP_WORK_DIR)\n",
    "\n",
    "    return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be899169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_test_images(test_json: Path) -> Dict[int, str]:\n",
    "    with open(test_json, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return {img[\"id\"]: img[\"file_name\"] for img in data[\"images\"]}\n",
    "\n",
    "def coco_bbox_json_to_prediction_dict(\n",
    "    bbox_json: Path,\n",
    "    test_json: Path,\n",
    "    score_thr: float = 0.05\n",
    ") -> Dict[str, str]:\n",
    "    id_to_fname = parse_test_images(test_json)\n",
    "\n",
    "    with open(bbox_json, \"r\") as f:\n",
    "        dets = json.load(f)\n",
    "\n",
    "    per_image = {}\n",
    "    for d in dets:\n",
    "        score = float(d.get(\"score\", 0.0))\n",
    "        if score < score_thr:\n",
    "            continue\n",
    "\n",
    "        img_id = int(d[\"image_id\"])\n",
    "        cat_id = int(d[\"category_id\"])\n",
    "\n",
    "        x, y, w, h = d[\"bbox\"]\n",
    "        x1, y1, x2, y2 = x, y, x + w, y + h\n",
    "\n",
    "        per_image.setdefault(img_id, []).append((cat_id, score, x1, y1, x2, y2))\n",
    "\n",
    "    pred_dict = {}\n",
    "    for img_id, fname in id_to_fname.items():\n",
    "        preds = per_image.get(img_id, [])\n",
    "        preds = sorted(preds, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        tokens = []\n",
    "        for cat, sc, x1, y1, x2, y2 in preds:\n",
    "            tokens.extend([\n",
    "                str(cat),\n",
    "                f\"{sc:.6f}\",\n",
    "                f\"{x1:.1f}\",\n",
    "                f\"{y1:.1f}\",\n",
    "                f\"{x2:.1f}\",\n",
    "                f\"{y2:.1f}\",\n",
    "            ])\n",
    "\n",
    "        pred_dict[fname] = \" \".join(tokens)\n",
    "\n",
    "    return pred_dict\n",
    "\n",
    "def save_submission_with_sample(\n",
    "    pred_dict: Dict[str, str],\n",
    "    sample_csv_path: Path,\n",
    "    out_csv_path: Path\n",
    ") -> None:\n",
    "    sample = pd.read_csv(sample_csv_path)\n",
    "\n",
    "    if \"image_id\" not in sample.columns or \"PredictionString\" not in sample.columns:\n",
    "        raise ValueError(f\"샘플 컬럼이 예상과 다름: {list(sample.columns)}\")\n",
    "\n",
    "    # 행/열 순서를 건드리지 않고 PredictionString만 교체\n",
    "    sample[\"PredictionString\"] = sample[\"image_id\"].map(lambda x: pred_dict.get(x, \"\"))\n",
    "\n",
    "    out_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sample.to_csv(out_csv_path, index=False)\n",
    "\n",
    "    print(\"Saved submission:\", out_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da7ffb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/06 09:52:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 427661093\n",
      "    GPU 0: Tesla V100-SXM2-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.1.2+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu121\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 427661093\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: gcc: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/06 09:52:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = '/data/ephemeral/home/model/dataset'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = '/data/ephemeral/home/model/work_dirs_single/cascade_rcnn_r50_1024_single/epoch_12.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        frozen_stages=1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=10,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.05,\n",
      "                        0.05,\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=10,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.033,\n",
      "                        0.033,\n",
      "                        0.067,\n",
      "                        0.067,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=10,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ],\n",
      "        type='CascadeRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(\n",
      "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    pos_iou_thr=0.6,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "        ],\n",
      "        rpn=dict(\n",
      "            allowed_border=0,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='CascadeRCNN')\n",
      "optim_wrapper = None\n",
      "param_scheduler = None\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='/data/ephemeral/home/model/dataset/test.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='/data/ephemeral/home/model/dataset',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='/data/ephemeral/home/model/dataset/test.json',\n",
      "    format_only=True,\n",
      "    metric='bbox',\n",
      "    outfile_prefix=\n",
      "    '/data/ephemeral/home/model/work_dirs_single/cascade_rcnn_r50_1024_single/cascade_rcnn_r50_1024_single_test',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = None\n",
      "train_dataloader = None\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = None\n",
      "val_dataloader = None\n",
      "val_evaluator = None\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/data/ephemeral/home/model/work_dirs_single/cascade_rcnn_r50_1024_single'\n",
      "\n",
      "12/06 09:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "12/06 09:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loads checkpoint by local backend from path: /data/ephemeral/home/model/work_dirs_single/cascade_rcnn_r50_1024_single/epoch_12.pth\n",
      "12/06 09:52:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /data/ephemeral/home/model/work_dirs_single/cascade_rcnn_r50_1024_single/epoch_12.pth\n",
      "12/06 09:52:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [  50/4871]    eta: 0:06:58  time: 0.0868  data_time: 0.0037  memory: 623  \n",
      "12/06 09:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 100/4871]    eta: 0:05:47  time: 0.0587  data_time: 0.0021  memory: 623  \n",
      "12/06 09:52:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 150/4871]    eta: 0:05:19  time: 0.0575  data_time: 0.0019  memory: 623  \n",
      "12/06 09:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 200/4871]    eta: 0:05:03  time: 0.0571  data_time: 0.0019  memory: 623  \n",
      "12/06 09:53:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 250/4871]    eta: 0:04:52  time: 0.0569  data_time: 0.0017  memory: 623  \n",
      "12/06 09:53:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 300/4871]    eta: 0:04:44  time: 0.0565  data_time: 0.0018  memory: 623  \n",
      "12/06 09:53:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 350/4871]    eta: 0:04:38  time: 0.0571  data_time: 0.0019  memory: 623  \n",
      "12/06 09:53:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 400/4871]    eta: 0:04:32  time: 0.0574  data_time: 0.0019  memory: 623  \n",
      "12/06 09:53:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 450/4871]    eta: 0:04:28  time: 0.0588  data_time: 0.0020  memory: 623  \n",
      "12/06 09:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 500/4871]    eta: 0:04:24  time: 0.0576  data_time: 0.0020  memory: 623  \n",
      "12/06 09:53:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 550/4871]    eta: 0:04:20  time: 0.0582  data_time: 0.0020  memory: 623  \n",
      "12/06 09:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 600/4871]    eta: 0:04:16  time: 0.0579  data_time: 0.0020  memory: 623  \n",
      "12/06 09:53:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 650/4871]    eta: 0:04:12  time: 0.0576  data_time: 0.0020  memory: 623  \n",
      "12/06 09:53:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 700/4871]    eta: 0:04:09  time: 0.0598  data_time: 0.0022  memory: 623  \n",
      "12/06 09:53:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 750/4871]    eta: 0:04:06  time: 0.0575  data_time: 0.0019  memory: 623  \n",
      "12/06 09:53:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 800/4871]    eta: 0:04:02  time: 0.0574  data_time: 0.0020  memory: 623  \n",
      "12/06 09:53:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 850/4871]    eta: 0:03:59  time: 0.0575  data_time: 0.0020  memory: 623  \n",
      "12/06 09:53:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 900/4871]    eta: 0:03:55  time: 0.0574  data_time: 0.0020  memory: 623  \n",
      "12/06 09:53:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 950/4871]    eta: 0:03:52  time: 0.0572  data_time: 0.0019  memory: 623  \n",
      "12/06 09:53:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1000/4871]    eta: 0:03:48  time: 0.0573  data_time: 0.0019  memory: 623  \n",
      "12/06 09:53:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1050/4871]    eta: 0:03:45  time: 0.0572  data_time: 0.0019  memory: 623  \n",
      "12/06 09:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1100/4871]    eta: 0:03:42  time: 0.0572  data_time: 0.0019  memory: 623  \n",
      "12/06 09:53:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1150/4871]    eta: 0:03:39  time: 0.0575  data_time: 0.0020  memory: 623  \n",
      "12/06 09:54:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1200/4871]    eta: 0:03:35  time: 0.0577  data_time: 0.0021  memory: 623  \n",
      "12/06 09:54:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1250/4871]    eta: 0:03:32  time: 0.0577  data_time: 0.0019  memory: 623  \n",
      "12/06 09:54:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1300/4871]    eta: 0:03:29  time: 0.0572  data_time: 0.0019  memory: 623  \n",
      "12/06 09:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1350/4871]    eta: 0:03:26  time: 0.0574  data_time: 0.0019  memory: 623  \n",
      "12/06 09:54:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1400/4871]    eta: 0:03:23  time: 0.0575  data_time: 0.0020  memory: 623  \n",
      "12/06 09:54:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1450/4871]    eta: 0:03:20  time: 0.0570  data_time: 0.0019  memory: 623  \n",
      "12/06 09:54:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1500/4871]    eta: 0:03:17  time: 0.0575  data_time: 0.0020  memory: 623  \n",
      "12/06 09:54:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1550/4871]    eta: 0:03:14  time: 0.0572  data_time: 0.0020  memory: 623  \n",
      "12/06 09:54:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1600/4871]    eta: 0:03:11  time: 0.0571  data_time: 0.0019  memory: 623  \n",
      "12/06 09:54:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1650/4871]    eta: 0:03:08  time: 0.0572  data_time: 0.0019  memory: 623  \n",
      "12/06 09:54:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1700/4871]    eta: 0:03:05  time: 0.0573  data_time: 0.0019  memory: 623  \n",
      "12/06 09:54:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1750/4871]    eta: 0:03:02  time: 0.0574  data_time: 0.0020  memory: 623  \n",
      "12/06 09:54:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1800/4871]    eta: 0:02:59  time: 0.0573  data_time: 0.0019  memory: 623  \n",
      "12/06 09:54:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1850/4871]    eta: 0:02:56  time: 0.0570  data_time: 0.0018  memory: 623  \n",
      "12/06 09:54:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1900/4871]    eta: 0:02:53  time: 0.0578  data_time: 0.0021  memory: 623  \n",
      "12/06 09:54:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1950/4871]    eta: 0:02:50  time: 0.0576  data_time: 0.0020  memory: 623  \n",
      "12/06 09:54:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2000/4871]    eta: 0:02:47  time: 0.0574  data_time: 0.0020  memory: 623  \n",
      "12/06 09:54:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2050/4871]    eta: 0:02:44  time: 0.0580  data_time: 0.0020  memory: 623  \n",
      "12/06 09:54:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2100/4871]    eta: 0:02:41  time: 0.0575  data_time: 0.0020  memory: 623  \n",
      "12/06 09:54:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2150/4871]    eta: 0:02:38  time: 0.0576  data_time: 0.0019  memory: 623  \n",
      "12/06 09:54:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2200/4871]    eta: 0:02:35  time: 0.0571  data_time: 0.0019  memory: 623  \n",
      "12/06 09:55:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2250/4871]    eta: 0:02:32  time: 0.0574  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2300/4871]    eta: 0:02:29  time: 0.0577  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2350/4871]    eta: 0:02:26  time: 0.0576  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2400/4871]    eta: 0:02:23  time: 0.0575  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2450/4871]    eta: 0:02:20  time: 0.0576  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2500/4871]    eta: 0:02:17  time: 0.0576  data_time: 0.0019  memory: 623  \n",
      "12/06 09:55:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2550/4871]    eta: 0:02:14  time: 0.0575  data_time: 0.0019  memory: 623  \n",
      "12/06 09:55:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2600/4871]    eta: 0:02:11  time: 0.0582  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2650/4871]    eta: 0:02:09  time: 0.0579  data_time: 0.0021  memory: 623  \n",
      "12/06 09:55:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2700/4871]    eta: 0:02:06  time: 0.0572  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2750/4871]    eta: 0:02:03  time: 0.0574  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2800/4871]    eta: 0:02:00  time: 0.0576  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2850/4871]    eta: 0:01:57  time: 0.0576  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2900/4871]    eta: 0:01:54  time: 0.0572  data_time: 0.0019  memory: 623  \n",
      "12/06 09:55:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2950/4871]    eta: 0:01:51  time: 0.0572  data_time: 0.0019  memory: 623  \n",
      "12/06 09:55:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3000/4871]    eta: 0:01:48  time: 0.0578  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3050/4871]    eta: 0:01:45  time: 0.0574  data_time: 0.0019  memory: 623  \n",
      "12/06 09:55:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3100/4871]    eta: 0:01:42  time: 0.0576  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3150/4871]    eta: 0:01:39  time: 0.0577  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3200/4871]    eta: 0:01:36  time: 0.0576  data_time: 0.0020  memory: 623  \n",
      "12/06 09:55:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3250/4871]    eta: 0:01:33  time: 0.0571  data_time: 0.0018  memory: 623  \n",
      "12/06 09:56:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3300/4871]    eta: 0:01:31  time: 0.0579  data_time: 0.0021  memory: 623  \n",
      "12/06 09:56:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3350/4871]    eta: 0:01:28  time: 0.0581  data_time: 0.0020  memory: 623  \n",
      "12/06 09:56:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3400/4871]    eta: 0:01:25  time: 0.0572  data_time: 0.0020  memory: 623  \n",
      "12/06 09:56:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3450/4871]    eta: 0:01:22  time: 0.0576  data_time: 0.0020  memory: 623  \n",
      "12/06 09:56:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3500/4871]    eta: 0:01:19  time: 0.0574  data_time: 0.0020  memory: 623  \n",
      "12/06 09:56:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3550/4871]    eta: 0:01:16  time: 0.0575  data_time: 0.0020  memory: 623  \n",
      "12/06 09:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3600/4871]    eta: 0:01:13  time: 0.0574  data_time: 0.0019  memory: 623  \n",
      "12/06 09:56:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3650/4871]    eta: 0:01:10  time: 0.0577  data_time: 0.0019  memory: 623  \n",
      "12/06 09:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3700/4871]    eta: 0:01:07  time: 0.0575  data_time: 0.0020  memory: 623  \n",
      "12/06 09:56:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3750/4871]    eta: 0:01:04  time: 0.0578  data_time: 0.0020  memory: 623  \n",
      "12/06 09:56:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3800/4871]    eta: 0:01:02  time: 0.0577  data_time: 0.0019  memory: 623  \n",
      "12/06 09:56:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3850/4871]    eta: 0:00:59  time: 0.0575  data_time: 0.0020  memory: 623  \n",
      "12/06 09:56:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3900/4871]    eta: 0:00:56  time: 0.0574  data_time: 0.0020  memory: 623  \n",
      "12/06 09:56:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [3950/4871]    eta: 0:00:53  time: 0.0575  data_time: 0.0019  memory: 623  \n",
      "12/06 09:56:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4000/4871]    eta: 0:00:50  time: 0.0576  data_time: 0.0019  memory: 623  \n",
      "12/06 09:56:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4050/4871]    eta: 0:00:47  time: 0.0575  data_time: 0.0019  memory: 623  \n",
      "12/06 09:56:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4100/4871]    eta: 0:00:44  time: 0.0571  data_time: 0.0018  memory: 623  \n",
      "12/06 09:56:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4150/4871]    eta: 0:00:41  time: 0.0568  data_time: 0.0017  memory: 623  \n",
      "12/06 09:56:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4200/4871]    eta: 0:00:38  time: 0.0568  data_time: 0.0017  memory: 623  \n",
      "12/06 09:56:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4250/4871]    eta: 0:00:35  time: 0.0569  data_time: 0.0019  memory: 623  \n",
      "12/06 09:56:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4300/4871]    eta: 0:00:33  time: 0.0573  data_time: 0.0019  memory: 623  \n",
      "12/06 09:57:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4350/4871]    eta: 0:00:30  time: 0.0573  data_time: 0.0018  memory: 623  \n",
      "12/06 09:57:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4400/4871]    eta: 0:00:27  time: 0.0577  data_time: 0.0019  memory: 623  \n",
      "12/06 09:57:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4450/4871]    eta: 0:00:24  time: 0.0575  data_time: 0.0019  memory: 623  \n",
      "12/06 09:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4500/4871]    eta: 0:00:21  time: 0.0576  data_time: 0.0019  memory: 623  \n",
      "12/06 09:57:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4550/4871]    eta: 0:00:18  time: 0.0578  data_time: 0.0020  memory: 623  \n",
      "12/06 09:57:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4600/4871]    eta: 0:00:15  time: 0.0575  data_time: 0.0020  memory: 623  \n",
      "12/06 09:57:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4650/4871]    eta: 0:00:12  time: 0.0575  data_time: 0.0020  memory: 623  \n",
      "12/06 09:57:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4700/4871]    eta: 0:00:09  time: 0.0578  data_time: 0.0020  memory: 623  \n",
      "12/06 09:57:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4750/4871]    eta: 0:00:06  time: 0.0581  data_time: 0.0021  memory: 623  \n",
      "12/06 09:57:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4800/4871]    eta: 0:00:04  time: 0.0576  data_time: 0.0020  memory: 623  \n",
      "12/06 09:57:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4850/4871]    eta: 0:00:01  time: 0.0575  data_time: 0.0019  memory: 623  \n",
      "12/06 09:57:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - results are saved in /data/ephemeral/home/model/work_dirs_single/cascade_rcnn_r50_1024_single\n",
      "12/06 09:57:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [4871/4871]    data_time: 0.0020  time: 0.0578\n",
      "bbox json: /data/ephemeral/home/model/work_dirs_single/cascade_rcnn_r50_1024_single/cascade_rcnn_r50_1024_single_test.bbox.json\n",
      "Saved submission: /data/ephemeral/home/model/work_dirs_single/cascade_rcnn_r50_1024_single/cascade_rcnn_r50_1024_single_submission_full.csv\n",
      "단일 모델 전체 테스트 추론 완료\n",
      "제출 파일: /data/ephemeral/home/model/work_dirs_single/cascade_rcnn_r50_1024_single/cascade_rcnn_r50_1024_single_submission_full.csv\n"
     ]
    }
   ],
   "source": [
    "test_cfg = build_test_cfg(ckpt)\n",
    "runner = Runner.from_cfg(test_cfg)\n",
    "\n",
    "# COCO bbox json 생성\n",
    "runner.test()\n",
    "\n",
    "# 생성된 bbox json 경로 탐색\n",
    "bbox_json = EXP_WORK_DIR / f\"{EXP_NAME}_test.bbox.json\"\n",
    "if not bbox_json.exists():\n",
    "    cand = sorted(EXP_WORK_DIR.glob(\"*_test.bbox.json\"))\n",
    "    if cand:\n",
    "        bbox_json = cand[-1]\n",
    "\n",
    "print(\"bbox json:\", bbox_json)\n",
    "if not bbox_json.exists():\n",
    "    raise FileNotFoundError(\"bbox json 생성 실패\")\n",
    "\n",
    "# PredictionString dict 생성\n",
    "pred_dict = coco_bbox_json_to_prediction_dict(\n",
    "    bbox_json=bbox_json,\n",
    "    test_json=TEST_JSON_FULL,\n",
    "    score_thr=0.05\n",
    ")\n",
    "\n",
    "# 최종 제출 저장\n",
    "out_csv = EXP_WORK_DIR / f\"{EXP_NAME}_submission_full.csv\"\n",
    "save_submission_with_sample(pred_dict, sample_csv, out_csv)\n",
    "\n",
    "print(\"단일 모델 전체 테스트 추론 완료\")\n",
    "print(\"제출 파일:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc7be63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
